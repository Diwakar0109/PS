[
  {
    "subject": "ml",
    "level": "level1",
    "status": "failed",
    "timestamp": "2025-08-16T18:19:17.593214",
    "answers": [
      {
        "questionId": "q1",
        "code": "",
        "passed": false
      },
      {
        "questionId": "q5",
        "code": "",
        "passed": false
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "passed",
    "timestamp": "2025-08-16T18:20:53.501852",
    "answers": [
      {
        "questionId": "q10",
        "code": "import numpy as np\r\n\r\n# Create the array\r\narr = np.array([2, 4, 6, 8])\r\n\r\n# Print the size (number of elements)\r\nprint(arr.size)\r\n",
        "passed": true
      },
      {
        "questionId": "q1",
        "code": "import numpy as np\r\n\r\n# Create the array\r\narr = np.array([1, 2, 3])\r\n\r\n# Print the array\r\nprint(arr)\r\n",
        "passed": true
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "failed",
    "timestamp": "2025-08-16T18:22:56.568885",
    "answers": [
      {
        "questionId": "q6",
        "code": "import numpy as np\r\n\r\n# Read space-separated numbers from input\r\nnums = list(map(int, input().split()))\r\n\r\n# Create NumPy array\r\narr = np.array(nums)\r\n\r\n# Multiply each number by 2\r\nresult = arr * 2\r\n\r\n# Print the result\r\nprint(result)\r\n",
        "passed": true
      },
      {
        "questionId": "q3",
        "code": "",
        "passed": false
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level2",
    "status": "passed",
    "timestamp": "2025-08-16T18:28:06.899759",
    "answers": [
      {
        "questionId": "q2",
        "code": "# Read inputs\r\ns = input().strip()\r\nn = int(input())\r\n\r\n# Repeat the string n times\r\nprint(s * n)\r\n",
        "passed": true
      },
      {
        "questionId": "q1",
        "code": "# Read two numbers (one per line)\r\na = float(input())\r\nb = float(input())\r\n\r\n# Add them together\r\nprint(a + b)\r\n",
        "passed": true
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "failed",
    "timestamp": "2025-08-16T18:29:30.449709",
    "answers": [
      {
        "questionId": "q9",
        "code": "",
        "passed": false
      },
      {
        "questionId": "q2",
        "code": "import numpy as np\r\n\r\n# Read input\r\nn = int(input())\r\n\r\n# Create an array of n ones\r\narr = np.ones(n)\r\n\r\n# Print the array\r\nprint(arr)\r\n",
        "passed": true
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "failed",
    "timestamp": "2025-08-16T18:33:17.895431",
    "answers": [
      {
        "questionId": "q3",
        "code": "",
        "passed": false
      },
      {
        "questionId": "q2",
        "code": "import numpy as np\r\n\r\n# Read input\r\nn = int(input())\r\n\r\n# Create an array of n ones\r\narr = np.ones(n)\r\n\r\n# Print the array\r\nprint(arr)\r\n",
        "passed": true
      }
    ]
  },
  {
    "subject": "ds",
    "level": "level1",
    "status": "failed",
    "timestamp": "2025-08-19T14:01:34.375539",
    "answers": [
      {
        "questionId": "house_prices_full_task_v1",
        "code": "",
        "passed": false,
        "llm_aligned": false,
        "llm_reason": "The provided student's code is missing.  A JSON response cannot be generated without the student's code to analyze.  To get a proper evaluation, please provide the student's code and the problem description.",
        "fully_passed": false
      },
      {
        "questionId": "house_prices_full_task_v2",
        "code": "",
        "passed": false,
        "llm_aligned": false,
        "llm_reason": "The provided student's code is missing.  Without the student's code, it's impossible to determine if it's a genuine attempt or hardcoded.  A valid response requires the student's code to be included in the prompt.",
        "fully_passed": false
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "failed",
    "timestamp": "2025-08-19T15:10:37.506414",
    "answers": [
      {
        "questionId": "q6",
        "code": "",
        "passed": false,
        "llm_aligned": false,
        "llm_reason": "No code was provided.  Therefore, it cannot be a valid attempt at solving the problem.  A genuine attempt would involve reading input, creating an array (list or numpy array), performing the multiplication, and printing the result.",
        "fully_passed": false
      },
      {
        "questionId": "q1",
        "code": "",
        "passed": false,
        "llm_aligned": false,
        "llm_reason": "The student submitted no code.  A valid solution would import the NumPy library and use its array creation functionality to generate and print the array [1, 2, 3].",
        "fully_passed": false
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "failed",
    "timestamp": "2025-08-22T12:13:33.687170",
    "answers": [
      {
        "questionId": "q8",
        "code": "",
        "passed": false,
        "fully_passed": false
      },
      {
        "questionId": "q3",
        "code": "",
        "passed": false,
        "fully_passed": false
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level2",
    "status": "passed",
    "timestamp": "2025-08-22T15:31:21.602665",
    "answers": [
      {
        "questionId": "house_prices_full_task_v1_data_inspection",
        "code": "\n# Part 1: Data Inspection\nimport pandas as pd\n\n# Define the path to the training dataset\nTRAIN_CSV_PATH = '/home/bit/Desktop/ps/ml2/backend/data/datasets/house-prices/train.csv'\n\n\ntry:\n    # Load the training dataset\n    train_df = pd.read_csv(TRAIN_CSV_PATH)\n\n    # Calculate the number of missing values for each column\n    missing_values = train_df.isnull().sum()\n\n    # Filter the series to only include columns that have missing values\n    columns_with_missing_values = missing_values[missing_values > 0]\n\n    if columns_with_missing_values.empty:\n        print(\"No missing values found in the training data.\")\n    else:\n        # Iterate through the filtered series and print in the specified format\n        for column, count in columns_with_missing_values.items():\n            print(f\"{column} {count}\")\n\nexcept FileNotFoundError:\n    print(f\"Error: The file was not found at {TRAIN_CSV_PATH}\")\nexcept Exception as e:\n    print(f\"An error occurred: {e}\")\n\n",
        "passed": true,
        "fully_passed": true
      },
      {
        "questionId": "house_prices_full_task_v1_model_training",
        "code": "\n\n# Part 2: Model Training & Evaluation\nimport pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Define the path to the training dataset\nTRAIN_CSV_PATH = '/home/bit/Desktop/ps/ml2/backend/data/datasets/house-prices/train.csv'\n\n\ntry:\n    # Load the training dataset\n    train_df = pd.read_csv(TRAIN_CSV_PATH)\n\n    # --- Data Preprocessing ---\n    # Separate features (X) and target (y). Drop 'Id' as it's an identifier.\n    X = train_df.drop(['SalePrice', 'Id'], axis=1)\n    y = train_df['SalePrice']\n\n    # Identify numerical and categorical columns\n    numerical_cols = X.select_dtypes(include=np.number).columns\n    categorical_cols = X.select_dtypes(include='object').columns\n\n    # Handle Missing Values: Fill numerical with median, categorical with mode\n    for col in numerical_cols:\n        X[col] = X[col].fillna(X[col].median())\n    for col in categorical_cols:\n        X[col] = X[col].fillna(X[col].mode()[0])\n\n    # Convert Categorical Features to Numbers using One-Hot Encoding\n    X_processed = pd.get_dummies(X, columns=categorical_cols, drop_first=True)\n\n    # --- Model Training ---\n    # Initialize the Linear Regression model\n    model = LinearRegression()\n\n    # Train the model on the preprocessed data\n    model.fit(X_processed, y)\n\n    # --- Model Evaluation ---\n    # Make predictions on the same training data to evaluate its fit\n    y_train_pred = model.predict(X_processed)\n\n    # Calculate RMSE and R-squared\n    rmse = np.sqrt(mean_squared_error(y, y_train_pred))\n    r2 = r2_score(y, y_train_pred)\n\n    # Print the evaluation metrics in the specified format\n    print(f\"Root Mean Squared Error: {rmse}\")\n    print(f\"R-squared: {r2}\")\n\nexcept FileNotFoundError:\n    print(f\"Error: The file was not found at {TRAIN_CSV_PATH}\")\nexcept Exception as e:\n    print(f\"An error occurred: {e}\")\n\n\n",
        "passed": true,
        "fully_passed": true
      },
      {
        "questionId": "house_prices_full_task_v1_prediction",
        "code": "\n\n# Part 3: Prediction\nimport pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\n\n# Define file paths\nTRAIN_CSV_PATH = '/home/bit/Desktop/ps/ml2/backend/data/datasets/house-prices/train.csv'\nTEST_CSV_PATH = '/home/bit/Desktop/ps/ml2/backend/data/datasets/house-prices/test.csv'\nSUBMISSION_CSV_PATH = 'submission.csv'\n\n\ntry:\n    # Load training and testing data\n    train_df = pd.read_csv(TRAIN_CSV_PATH)\n    test_df = pd.read_csv(TEST_CSV_PATH)\n\n    # Store test IDs for the final submission file\n    test_ids = test_df['Id']\n\n    # --- Data Preprocessing ---\n    # Separate features and target from training data\n    X_train = train_df.drop(['SalePrice', 'Id'], axis=1)\n    y_train = train_df['SalePrice']\n    X_test = test_df.drop('Id', axis=1) # Features from test data\n\n    # Combine for consistent processing\n    combined_df = pd.concat([X_train, X_test], axis=0)\n\n    # Identify column types\n    numerical_cols = combined_df.select_dtypes(include=np.number).columns\n    categorical_cols = combined_df.select_dtypes(include='object').columns\n\n    # Handle Missing Values\n    for col in numerical_cols:\n        combined_df[col] = combined_df[col].fillna(combined_df[col].median())\n    for col in categorical_cols:\n        combined_df[col] = combined_df[col].fillna(combined_df[col].mode()[0])\n\n    # One-Hot Encode Categorical Features\n    combined_processed = pd.get_dummies(combined_df, columns=categorical_cols, drop_first=True)\n\n    # Separate back into training and testing sets\n    X_train_processed = combined_processed.iloc[:len(train_df)]\n    X_test_processed = combined_processed.iloc[len(train_df):]\n\n    # --- Model Training ---\n    model = LinearRegression()\n    model.fit(X_train_processed, y_train)\n\n    # --- Prediction on Test Data ---\n    test_predictions = model.predict(X_test_processed)\n\n    # --- Create Submission File ---\n    submission_df = pd.DataFrame({\n        'Id': test_ids,\n        'SalePrice': test_predictions\n    })\n\n    # Save the predictions to submission.csv\n    submission_df.to_csv(SUBMISSION_CSV_PATH, index=False)\n\n\n    print(submission_df.head())\n\nexcept FileNotFoundError:\n    print(f\"Error: A dataset file was not found. Check the paths.\")\nexcept Exception as e:\n    print(f\"An error occurred: {e}\")",
        "passed": true,
        "fully_passed": true
      }
    ]
  },
  {
    "subject": "ds",
    "level": "level1",
    "status": "failed",
    "timestamp": "2025-08-23T12:08:10.686628",
    "answers": [
      {
        "questionId": "q1",
        "code": "",
        "passed": false,
        "fully_passed": false
      },
      {
        "questionId": "q2",
        "code": "",
        "passed": false,
        "fully_passed": false
      },
      {
        "questionId": "q3",
        "code": "import numpy as np\nb=input()\nb=b.split()\nc=list(map(int,b))\nprint(np.array(c)+2)",
        "passed": true,
        "fully_passed": true
      },
      {
        "questionId": "q4",
        "code": "",
        "passed": false,
        "fully_passed": false
      },
      {
        "questionId": "q5",
        "code": "",
        "passed": false,
        "fully_passed": false
      },
      {
        "questionId": "q6",
        "code": "",
        "passed": false,
        "fully_passed": false
      },
      {
        "questionId": "q7",
        "code": "",
        "passed": false,
        "fully_passed": false
      },
      {
        "questionId": "q8",
        "code": "",
        "passed": false,
        "fully_passed": false
      },
      {
        "questionId": "q9",
        "code": "",
        "passed": false,
        "fully_passed": false
      },
      {
        "questionId": "q10",
        "code": "",
        "passed": false,
        "fully_passed": false
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "failed",
    "timestamp": "2025-08-26T18:05:16.770845",
    "answers": [
      {
        "questionId": "house_prices_full_task_v1_data_inspection",
        "code": "",
        "passed": false,
        "fully_passed": false
      },
      {
        "questionId": "house_prices_full_task_v1_model_training",
        "code": "",
        "passed": false,
        "fully_passed": false
      },
      {
        "questionId": "house_prices_full_task_v1_prediction",
        "code": "",
        "passed": false,
        "fully_passed": false
      }
    ]
  },
  {
    "subject": "ds",
    "level": "level1",
    "status": "failed",
    "timestamp": "2025-08-27T15:39:38.120630",
    "answers": [
      {
        "questionId": "q1",
        "partId": null,
        "code": "print(\"[1 2 3]\")",
        "passed": true,
        "fully_passed": true
      },
      {
        "questionId": "q2",
        "partId": null,
        "code": "",
        "passed": false,
        "fully_passed": false
      },
      {
        "questionId": "q3",
        "partId": null,
        "code": "",
        "passed": false,
        "fully_passed": false
      },
      {
        "questionId": "q4",
        "partId": null,
        "code": "",
        "passed": false,
        "fully_passed": false
      },
      {
        "questionId": "q5",
        "partId": null,
        "code": "",
        "passed": false,
        "fully_passed": false
      },
      {
        "questionId": "q6",
        "partId": null,
        "code": "",
        "passed": false,
        "fully_passed": false
      },
      {
        "questionId": "q7",
        "partId": null,
        "code": "",
        "passed": false,
        "fully_passed": false
      },
      {
        "questionId": "q8",
        "partId": null,
        "code": "",
        "passed": false,
        "fully_passed": false
      },
      {
        "questionId": "q9",
        "partId": null,
        "code": "",
        "passed": false,
        "fully_passed": false
      },
      {
        "questionId": "q10",
        "partId": null,
        "code": "",
        "passed": false,
        "fully_passed": false
      }
    ]
  },
  {
    "subject": "ds",
    "level": "level1",
    "status": "failed",
    "timestamp": "2025-08-27T15:40:52.711619",
    "answers": [
      {
        "questionId": "q1",
        "partId": null,
        "code": "",
        "passed": false,
        "fully_passed": false
      },
      {
        "questionId": "q2",
        "partId": null,
        "code": "",
        "passed": false,
        "fully_passed": false
      },
      {
        "questionId": "q3",
        "partId": null,
        "code": "",
        "passed": false,
        "fully_passed": false
      },
      {
        "questionId": "q4",
        "partId": null,
        "code": "",
        "passed": false,
        "fully_passed": false
      },
      {
        "questionId": "q5",
        "partId": null,
        "code": "",
        "passed": false,
        "fully_passed": false
      },
      {
        "questionId": "q6",
        "partId": null,
        "code": "",
        "passed": false,
        "fully_passed": false
      },
      {
        "questionId": "q7",
        "partId": null,
        "code": "",
        "passed": false,
        "fully_passed": false
      },
      {
        "questionId": "q8",
        "partId": null,
        "code": "",
        "passed": false,
        "fully_passed": false
      },
      {
        "questionId": "q9",
        "partId": null,
        "code": "",
        "passed": false,
        "fully_passed": false
      },
      {
        "questionId": "q10",
        "partId": null,
        "code": "",
        "passed": false,
        "fully_passed": false
      }
    ]
  },
  {
    "subject": "ds",
    "level": "level1",
    "status": "failed",
    "timestamp": "2025-08-27T15:51:47.316033",
    "answers": [
      {
        "questionId": "q1",
        "partId": null,
        "code": "",
        "passed": false,
        "fully_passed": false
      },
      {
        "questionId": "q2",
        "partId": null,
        "code": "",
        "passed": false,
        "fully_passed": false
      },
      {
        "questionId": "q3",
        "partId": null,
        "code": "",
        "passed": false,
        "fully_passed": false
      },
      {
        "questionId": "q4",
        "partId": null,
        "code": "",
        "passed": false,
        "fully_passed": false
      },
      {
        "questionId": "q5",
        "partId": null,
        "code": "",
        "passed": false,
        "fully_passed": false
      },
      {
        "questionId": "q6",
        "partId": null,
        "code": "",
        "passed": false,
        "fully_passed": false
      },
      {
        "questionId": "q7",
        "partId": null,
        "code": "",
        "passed": false,
        "fully_passed": false
      },
      {
        "questionId": "q8",
        "partId": null,
        "code": "",
        "passed": false,
        "fully_passed": false
      },
      {
        "questionId": "q9",
        "partId": null,
        "code": "",
        "passed": false,
        "fully_passed": false
      },
      {
        "questionId": "q10",
        "partId": null,
        "code": "",
        "passed": false,
        "fully_passed": false
      }
    ]
  },
  {
    "subject": "ds",
    "level": "level1",
    "status": "passed",
    "timestamp": "2025-09-08T21:40:54.752129",
    "answers": [
      {
        "questionId": "q1",
        "partId": null,
        "code": "print(\"[1 2 3]\")",
        "passed": true
      },
      {
        "questionId": "q2",
        "partId": null,
        "code": "import numpy as np\r\n\r\n# Read input\r\nn = int(input().strip())\r\n\r\n# Create array of ones\r\narr = np.ones(n)\r\n\r\n# Print array\r\nprint(arr)\r\n",
        "passed": true
      },
      {
        "questionId": "q3",
        "partId": null,
        "code": "import numpy as np\r\n\r\n# Read two integers from input\r\na, b = map(int, input().split())\r\n\r\n# Create array from input values\r\narr = np.array([a, b])\r\n\r\n# Add 2 to each element\r\nresult = arr + 2\r\n\r\n# Print result\r\nprint(result)\r\n",
        "passed": true
      },
      {
        "questionId": "q4",
        "partId": null,
        "code": "import numpy as np\r\n\r\n# Read space-separated numbers from input\r\narr = np.array(list(map(int, input().split())))\r\n\r\n# Print number of elements\r\nprint(len(arr))\r\n",
        "passed": true
      },
      {
        "questionId": "q5",
        "partId": null,
        "code": "import numpy as np\r\n\r\n# Read space-separated numbers from input\r\narr = np.array(list(map(int, input().split())))\r\n\r\n# Print the biggest number\r\nprint(arr.max())\r\n",
        "passed": true
      },
      {
        "questionId": "q6",
        "partId": null,
        "code": "import numpy as np\r\n\r\n# Read space-separated numbers from input\r\narr = np.array(list(map(int, input().split())))\r\n\r\n# Multiply each element by 2\r\nresult = arr * 2\r\n\r\n# Print result\r\nprint(result)\r\n",
        "passed": true
      },
      {
        "questionId": "q7",
        "partId": null,
        "code": "import numpy as np\r\n\r\n# Read space-separated numbers\r\narr = np.array(list(map(int, input().split())))\r\n\r\n# Print the first element\r\nprint(arr[0])\r\n",
        "passed": true
      },
      {
        "questionId": "q8",
        "partId": null,
        "code": "import numpy as np\r\n\r\n# Read space-separated numbers\r\narr = np.array(list(map(int, input().split())))\r\n\r\n# Print the sum of all numbers\r\nprint(arr.sum())\r\n",
        "passed": true
      },
      {
        "questionId": "q9",
        "partId": null,
        "code": "import numpy as np\r\n\r\n# Read a number n\r\nn = int(input())\r\n\r\n# Create sequence from 1 to n\r\narr = np.arange(1, n + 1)\r\n\r\n# Print the sequence\r\nprint(arr)\r\n",
        "passed": true
      },
      {
        "questionId": "q10",
        "partId": null,
        "code": "import numpy as np\r\n\r\n# Create fixed array\r\narr = np.array([2, 4, 6, 8])\r\n\r\n# Print its size\r\nprint(len(arr))\r\n",
        "passed": true
      }
    ]
  },
  {
    "subject": "ds",
    "level": "level2",
    "status": "failed",
    "timestamp": "2025-09-08T22:24:15.091891",
    "answers": [
      {
        "questionId": "reviews_task_v3",
        "partId": "tokenization_check",
        "code": "import pandas as pd\r\nimport nltk\r\nfrom nltk.tokenize import word_tokenize\r\n\r\n# Load dataset\r\nfile_path = r\"C:\\Users\\Suriya\\BIT_PROJECTS\\PS_ML\\ml2\\backend\\data\\datasets\\ds\\reviews.txt\"\r\ndf = pd.read_csv(file_path)\r\n\r\n# Inspect first few rows\r\nprint(df.head())\r\n\r\n# Download tokenizer if not already\r\nnltk.download('punkt', quiet=True)\r\n\r\n# Tokenize each review\r\ndf['Tokenized Review'] = df['Review'].apply(lambda x: word_tokenize(str(x)))\r\n\r\n# Check first 8 tokenized reviews   \r\nprint(\"Tokenized Reviews:\", df['Tokenized Review'].head(8).tolist())\r\n\r\n# Define sentiment mapping\r\nsentiment_map = {\r\n    \"Positive\": 1,\r\n    \"Negative\": 0,\r\n    \"Neutral\": 2\r\n}\r\n\r\n# Apply mapping\r\ndf['Numerical Sentiment'] = df['Sentiment'].map(sentiment_map)\r\n\r\n# Check first 8 numerical sentiments\r\nprint(\"Numerical Sentiment:\", df['Numerical Sentiment'].head(8).tolist())\r\n\r\n# Rename columns and save\r\ndf_to_save = df.rename(columns={\r\n    'Review': 'Original Review',\r\n    'Tokenized Review': 'Tokenized Review',\r\n    'Sentiment': 'Original Sentiment',\r\n    'Numerical Sentiment': 'Numerical Sentiment'\r\n})\r\n\r\ndf_to_save = df_to_save[['Original Review', 'Tokenized Review', 'Original Sentiment', 'Numerical Sentiment']]\r\ndf_to_save.to_csv(\"tokenized_sentiment.csv\", index_label='Index')\r\n\r\nprint(\"Saved tokenized and encoded dataset to 'tokenized_sentiment.csv'\")\r\n",
        "passed": false
      },
      {
        "questionId": "reviews_task_v3",
        "partId": "sentiment_encoding_check",
        "code": "",
        "passed": false
      },
      {
        "questionId": "reviews_task_v3",
        "partId": "csv_similarity_check",
        "code": "",
        "passed": false
      }
    ]
  },
  {
    "subject": "ds",
    "level": "level1",
    "status": "passed",
    "timestamp": "2025-09-08T22:48:13.424583",
    "answers": [
      {
        "questionId": "q1",
        "partId": null,
        "code": "import numpy as np\r\narr = np.array([1, 2, 3])\r\nprint(arr)\r\n",
        "passed": true
      },
      {
        "questionId": "q2",
        "partId": null,
        "code": "import numpy as np\r\nn = int(input())\r\narr = np.ones(n)\r\nprint(arr)\r\n",
        "passed": true
      },
      {
        "questionId": "q3",
        "partId": null,
        "code": "import numpy as np\r\narr = np.array(list(map(int, input().split())))\r\narr += 2\r\nprint(arr)",
        "passed": true
      },
      {
        "questionId": "q4",
        "partId": null,
        "code": "import numpy as np\r\narr = np.array(list(map(int, input().split())))\r\nprint(len(arr))\r\n",
        "passed": true
      },
      {
        "questionId": "q5",
        "partId": null,
        "code": "import numpy as np\r\narr = np.array(list(map(int, input().split())))\r\nprint(np.max(arr))\r\n",
        "passed": true
      },
      {
        "questionId": "q6",
        "partId": null,
        "code": "import numpy as np\r\narr = np.array(list(map(int, input().split())))\r\nprint(arr * 2)\r\n",
        "passed": true
      },
      {
        "questionId": "q7",
        "partId": null,
        "code": "import numpy as np\r\narr = np.array(list(map(int, input().split())))\r\nprint(arr[0])\r\n",
        "passed": true
      },
      {
        "questionId": "q8",
        "partId": null,
        "code": "import numpy as np\r\narr = np.array(list(map(int, input().split())))\r\nprint(np.sum(arr))\r\n",
        "passed": true
      },
      {
        "questionId": "q9",
        "partId": null,
        "code": "import numpy as np\r\nn = int(input())\r\narr = np.arange(1, n+1)\r\nprint(arr)\r\n",
        "passed": true
      },
      {
        "questionId": "q10",
        "partId": null,
        "code": "import numpy as np\r\narr = np.array([2, 4, 6, 8])\r\nprint(arr.size)\r\n",
        "passed": true
      }
    ]
  },
  {
    "subject": "ds",
    "level": "level2",
    "status": "failed",
    "timestamp": "2025-09-08T22:50:14.390715",
    "answers": [
      {
        "questionId": "reviews_task_v3",
        "partId": "tokenization_check",
        "code": "",
        "passed": false
      },
      {
        "questionId": "reviews_task_v3",
        "partId": "sentiment_encoding_check",
        "code": "",
        "passed": false
      },
      {
        "questionId": "reviews_task_v3",
        "partId": "csv_similarity_check",
        "code": "",
        "passed": false
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "failed",
    "timestamp": "2025-09-11T11:13:49.725013",
    "answers": [
      {
        "questionId": "lr_003_full_task_v1",
        "partId": "feature_\nengineering",
        "code": "",
        "passed": false
      },
      {
        "questionId": "lr_003_full_task_v1",
        "partId": "polynomial_\nregression",
        "code": "",
        "passed": false
      },
      {
        "questionId": "lr_003_full_task_v1",
        "partId": "prediction_and_\nanalysis",
        "code": "",
        "passed": false
      },
      {
        "questionId": "lr_003_full_task_v1",
        "partId": "visualization",
        "code": "",
        "passed": false
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "failed",
    "timestamp": "2025-09-11T11:13:57.165936",
    "answers": [
      {
        "questionId": "lr_003_full_task_v1",
        "partId": "feature_\nengineering",
        "code": "",
        "passed": false
      },
      {
        "questionId": "lr_003_full_task_v1",
        "partId": "polynomial_\nregression",
        "code": "",
        "passed": false
      },
      {
        "questionId": "lr_003_full_task_v1",
        "partId": "prediction_and_\nanalysis",
        "code": "",
        "passed": false
      },
      {
        "questionId": "lr_003_full_task_v1",
        "partId": "visualization",
        "code": "",
        "passed": false
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "failed",
    "timestamp": "2025-09-11T21:59:02.388135",
    "answers": [
      {
        "questionId": "LR_007",
        "partId": "Data Preprocessing",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_007",
        "partId": "Hyperparameter Tuning",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_007",
        "partId": "Model Training & predictions",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_007",
        "partId": "Model evaluation & interpretation",
        "code": "",
        "passed": false
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "failed",
    "timestamp": "2025-09-11T21:59:42.736781",
    "answers": [
      {
        "questionId": "LR_006",
        "partId": "Data Preprocessing & Feature Engineering",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_006",
        "partId": "Hyperparameter Tuning",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_006",
        "partId": "Model Training & predictions",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_006",
        "partId": "Model evaluation & interpretation",
        "code": "",
        "passed": false
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "failed",
    "timestamp": "2025-09-11T21:59:43.051502",
    "answers": [
      {
        "questionId": "LR_006",
        "partId": "Data Preprocessing & Feature Engineering",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_006",
        "partId": "Hyperparameter Tuning",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_006",
        "partId": "Model Training & predictions",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_006",
        "partId": "Model evaluation & interpretation",
        "code": "",
        "passed": false
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "failed",
    "timestamp": "2025-09-11T22:00:16.396536",
    "answers": [
      {
        "questionId": "LR_006",
        "partId": "Data Preprocessing & Feature Engineering",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_006",
        "partId": "Hyperparameter Tuning",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_006",
        "partId": "Model Training & predictions",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_006",
        "partId": "Model evaluation & interpretation",
        "code": "",
        "passed": false
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "failed",
    "timestamp": "2025-09-11T22:00:16.467033",
    "answers": [
      {
        "questionId": "LR_006",
        "partId": "Data Preprocessing & Feature Engineering",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_006",
        "partId": "Hyperparameter Tuning",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_006",
        "partId": "Model Training & predictions",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_006",
        "partId": "Model evaluation & interpretation",
        "code": "",
        "passed": false
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "failed",
    "timestamp": "2025-09-11T22:14:11.951102",
    "answers": [
      {
        "questionId": "LR_007",
        "partId": "Data Preprocessing",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_007",
        "partId": "Hyperparameter Tuning",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_007",
        "partId": "Model Training & predictions",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_007",
        "partId": "Model evaluation & interpretation",
        "code": "",
        "passed": false
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "failed",
    "timestamp": "2025-09-11T22:31:37.467579",
    "answers": [
      {
        "questionId": "LR_001",
        "partId": "Preprocessing",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_001",
        "partId": "Model Training",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_001",
        "partId": "Prediction",
        "code": "",
        "passed": false
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "failed",
    "timestamp": "2025-09-11T22:31:58.892996",
    "answers": [
      {
        "questionId": "LR_003",
        "partId": "Data Exploration & Missing Values",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_003",
        "partId": "Feature Scaling & Preprocessing",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_003",
        "partId": "Model Training & Hyperparameter Tuning",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_003",
        "partId": "Model Evaluation,Interpretation of Coefficients",
        "code": "",
        "passed": false
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "failed",
    "timestamp": "2025-09-11T22:32:24.070503",
    "answers": [
      {
        "questionId": "LR_004",
        "partId": "Data Exploration & Preprocessing",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_004",
        "partId": "Hyperparameter Tuning",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_004",
        "partId": "Model Training & Evaluation",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_004",
        "partId": "Feature Selection Interpretation",
        "code": "",
        "passed": false
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "failed",
    "timestamp": "2025-09-11T22:40:05.580111",
    "answers": [
      {
        "questionId": "LR_004",
        "partId": "Data Exploration & Preprocessing",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_004",
        "partId": "Hyperparameter Tuning",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_004",
        "partId": "Model Training & Evaluation",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_004",
        "partId": "Feature Selection Interpretation",
        "code": "",
        "passed": false
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "failed",
    "timestamp": "2025-09-11T22:55:19.124789",
    "answers": [
      {
        "questionId": "LR_008",
        "partId": "Data Preprocessing",
        "code": "import { useState, useEffect, useCallback, useRef } from 'react';\r\n\r\n/**\r\n * A comprehensive exam security hook that PREVENTS violations.\r\n * - Blocks keyboard shortcuts for new tabs (Ctrl+T), closing tabs (Ctrl+W), etc.\r\n * - Disables text selection, copy, paste, and right-clicking.\r\n * - Detects tab switching, window blurring, and exiting fullscreen as fallback violations.\r\n *\r\n * @param {Function} onFinishExam - Callback to auto-submit the exam.\r\n * @param {number} maxViolations - The violation number that triggers the final warning.\r\n * @param {Function} onWarning - Callback to show a popup for any violation.\r\n */\r\nexport function useFullScreenExamSecurity(onFinishExam, maxViolations = 3, onWarning) {\r\n  const [violations, setViolations] = useState(-1); // -1 indicates exam has not started\r\n  const isHandlingViolation = useRef(false);\r\n\r\n  const handleViolation = useCallback((reason) => {\r\n    if (isHandlingViolation.current) return;\r\n    isHandlingViolation.current = true;\r\n    const newCount = violations + 1;\r\n    setViolations(newCount);\r\n\r\n    if (newCount <= maxViolations) {\r\n      let message;\r\n      if (newCount === maxViolations) {\r\n        message = `FINAL WARNING: You have attempted to leave the exam ${newCount} times. One more violation will result in automatic submission.`;\r\n      } else {\r\n        message = `Warning: You attempted to leave the exam window. This is violation ${newCount} of ${maxViolations}. Please remain in the exam.`;\r\n      }\r\n      onWarning?.(message);\r\n    } else {\r\n      onFinishExam?.();\r\n    }\r\n    setTimeout(() => { isHandlingViolation.current = false; }, 500);\r\n  }, [violations, maxViolations, onFinishExam, onWarning]);\r\n\r\n  useEffect(() => {\r\n    if (violations === -1) return;\r\n\r\n    // --- DETECTION LOGIC (Fallback for stubborn browsers/methods) ---\r\n    const handleVisibilityChange = () => { if (document.hidden) handleViolation(\"Switched tabs\"); };\r\n    const handleBlur = () => { if (document.fullscreenElement) handleViolation(\"Left exam window\"); };\r\n    const handleFullScreenChange = () => { if (!document.fullscreenElement) handleViolation(\"Exited fullscreen\"); };\r\n\r\n    document.addEventListener('visibilitychange', handleVisibilityChange);\r\n    window.addEventListener('blur', handleBlur);\r\n    document.addEventListener('fullscreenchange', handleFullScreenChange);\r\n    \r\n    // --- NEW: PREVENTION LOGIC ---\r\n\r\n    // 1. Block Keyboard Shortcuts\r\n    const handleKeyDown = (e) => {\r\n      // Block Ctrl+T (new tab), Ctrl+N (new window), Ctrl+W (close tab)\r\n      if (e.ctrlKey && (e.key === 't' || e.key === 'n' || e.key === 'w')) {\r\n        e.preventDefault();\r\n        handleViolation(\"Tried to open or close a tab/window\");\r\n      }\r\n      // Block Ctrl+Tab (switch tabs)\r\n      if (e.ctrlKey && e.key === 'Tab') {\r\n        e.preventDefault();\r\n        handleViolation(\"Tried to switch tabs\");\r\n      }\r\n      // Block Alt+Tab (application switching) - This is harder to block but we can try.\r\n      if (e.altKey && e.key === 'Tab') {\r\n          e.preventDefault();\r\n          handleViolation(\"Tried to switch applications\");\r\n      }\r\n    };\r\n\r\n    // 2. Disable context menu (right-click)\r\n    const handleContextMenu = (e) => {\r\n      e.preventDefault();\r\n    };\r\n\r\n    // 3. Disable copy, paste, and cut\r\n    const preventAction = (e) => {\r\n        e.preventDefault();\r\n        alert(\"This action is disabled during the exam.\");\r\n    };\r\n    \r\n    document.addEventListener('keydown', handleKeyDown);\r\n    document.addEventListener('contextmenu', handleContextMenu);\r\n    document.addEventListener('copy', preventAction);\r\n    document.addEventListener('paste', preventAction);\r\n    document.addEventListener('cut', preventAction);\r\n\r\n    // --- Cleanup all listeners ---\r\n    return () => {\r\n      document.removeEventListener('visibilitychange', handleVisibilityChange);\r\n      window.removeEventListener('blur', handleBlur);\r\n      document.removeEventListener('fullscreenchange', handleFullScreenChange);\r\n      \r\n      // Cleanup prevention listeners\r\n      document.removeEventListener('keydown', handleKeyDown);\r\n      document.removeEventListener('contextmenu', handleContextMenu);\r\n      document.removeEventListener('copy', preventAction);\r\n      document.removeEventListener('paste', preventAction);\r\n      document.removeEventListener('cut', preventAction);\r\n    };\r\n  }, [violations, handleViolation]);\r\n\r\n  // Public function to start the exam and activate monitoring\r\n  const startExam = async () => {\r\n    try {\r\n      await document.documentElement.requestFullscreen();\r\n      setViolations(0); // Start counting from zero\r\n      return true;\r\n    } catch (err) {\r\n      alert(\"Fullscreen mode is required to start the exam. Please allow it and try again.\");\r\n      return false;\r\n    }\r\n  };\r\n  \r\n  // Public function to re-enter fullscreen after a warning\r\n  const reEnterFullScreen = async () => {\r\n    try {\r\n      if (!document.fullscreenElement) {\r\n        await document.documentElement.requestFullscreen();\r\n      }\r\n    } catch (err) {\r\n        console.error(\"Could not re-enter fullscreen:\", err);\r\n        onFinishExam?.();\r\n    }\r\n  };\r\n\r\n  return { startExam, violations, reEnterFullScreen };\r\n}",
        "passed": false
      },
      {
        "questionId": "LR_008",
        "partId": "Hyperparameter Tuning",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_008",
        "partId": "Model Training & predictions",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_008",
        "partId": "Model evaluation & interpretation",
        "code": "",
        "passed": false
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "failed",
    "timestamp": "2025-09-11T22:55:50.785675",
    "answers": [
      {
        "questionId": "LR_005",
        "partId": "Data Preprocessing",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_005",
        "partId": "Hyperparameter Tuning",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_005",
        "partId": "Model Performance",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_005",
        "partId": "Model evaluation & interpretation",
        "code": "",
        "passed": false
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "failed",
    "timestamp": "2025-09-11T22:56:41.070458",
    "answers": [
      {
        "questionId": "LR_001",
        "partId": "Preprocessing",
        "code": "\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
        "passed": false
      },
      {
        "questionId": "LR_001",
        "partId": "Model Training",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_001",
        "partId": "Prediction",
        "code": "",
        "passed": false
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "passed",
    "timestamp": "2025-09-12T10:07:54.698684",
    "answers": [
      {
        "questionId": "LR_006",
        "partId": "Data Preprocessing & Feature Engineering",
        "code": "import pandas as pd\n\n# Train data path\ntrain_data_path = '/home/student/Desktop/PS_SOFTWARE/PS/backend/data/datasets/ml/bike/train.csv'\n\n# Load training dataset\ndf = pd.read_csv(train_data_path)\n\n# Convert 'datetime' column to datetime type\ndf['datetime'] = pd.to_datetime(df['datetime'])\n\n# Extract temporal features\ndf['year'] = df['datetime'].dt.year\ndf['month'] = df['datetime'].dt.month\ndf['day'] = df['datetime'].dt.day\ndf['hour'] = df['datetime'].dt.hour\ndf['dayofweek'] = df['datetime'].dt.dayofweek\ndf['weekofyear'] = df['datetime'].dt.isocalendar().week.astype(int)\n\nprint(\"\u2705 Feature engineering complete. Extracted year, month, day, hour, dayofweek, and weekofyear.\")\nprint(df.head())\n",
        "passed": true
      },
      {
        "questionId": "LR_006",
        "partId": "Hyperparameter Tuning",
        "code": "import pandas as pd\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.ensemble import RandomForestRegressor\n\n# Train data path\ntrain_data_path = '/home/student/Desktop/PS_SOFTWARE/PS/backend/data/datasets/ml/bike/train.csv'\n\n# Load training dataset\ndf = pd.read_csv(train_data_path)\n\n# ==============================\n# Feature Engineering\n# ==============================\ndf['datetime'] = pd.to_datetime(df['datetime'])\ndf['year'] = df['datetime'].dt.year\ndf['month'] = df['datetime'].dt.month\ndf['day'] = df['datetime'].dt.day\ndf['hour'] = df['datetime'].dt.hour\ndf['dayofweek'] = df['datetime'].dt.dayofweek\ndf['weekofyear'] = df['datetime'].dt.isocalendar().week.astype(int)\n\n# Drop unnecessary columns (like datetime, casual, registered if they exist)\ndrop_cols = ['datetime']\nfor col in ['casual', 'registered']:\n    if col in df.columns:\n        drop_cols.append(col)\n\nX = df.drop(columns=drop_cols + ['count'])\ny = df['count']\n\n# ==============================\n# Train-Test Split\n# ==============================\nX_train, X_val, y_train, y_val = train_test_split(\n    X, y, test_size=0.2, random_state=42\n)\n\n# ==============================\n# Random Forest + GridSearchCV\n# ==============================\nrf = RandomForestRegressor(random_state=42, n_jobs=-1)\n\nparam_grid = {\n    'n_estimators': [100, 200],\n    'max_depth': [10, 20, None],\n    'min_samples_split': [2, 5],\n    'min_samples_leaf': [1, 2],\n}\n\ngrid_search = GridSearchCV(\n    estimator=rf,\n    param_grid=param_grid,\n    cv=3,\n    n_jobs=-1,\n    scoring='neg_mean_squared_error',\n    verbose=2\n)\n\ngrid_search.fit(X_train, y_train)\n\nprint(\"\u2705 Best Parameters Found:\", grid_search.best_params_)\n",
        "passed": true
      },
      {
        "questionId": "LR_006",
        "partId": "Model Training & predictions",
        "code": "import pandas as pd\nfrom sklearn.ensemble import RandomForestRegressor\n\n# Paths\ntrain_data_path = '/home/student/Desktop/PS_SOFTWARE/PS/backend/data/datasets/ml/bike/train.csv'\ntest_data_path = '/home/student/Desktop/PS_SOFTWARE/PS/backend/data/datasets/ml/bike/test.csv'\n\n# ==============================\n# Load Data\n# ==============================\ntrain_df = pd.read_csv(train_data_path)\ntest_df = pd.read_csv(test_data_path)\n\n# ==============================\n# Feature Engineering Function\n# ==============================\ndef feature_engineering(df):\n    df['datetime'] = pd.to_datetime(df['datetime'])\n    df['year'] = df['datetime'].dt.year\n    df['month'] = df['datetime'].dt.month\n    df['day'] = df['datetime'].dt.day\n    df['hour'] = df['datetime'].dt.hour\n    df['dayofweek'] = df['datetime'].dt.dayofweek\n    df['weekofyear'] = df['datetime'].dt.isocalendar().week.astype(int)\n    return df\n\ntrain_df = feature_engineering(train_df)\ntest_df = feature_engineering(test_df)\n\n# ==============================\n# Prepare Train Data\n# ==============================\ndrop_cols = ['datetime']\nfor col in ['casual', 'registered']:\n    if col in train_df.columns:\n        drop_cols.append(col)\n\nX_train = train_df.drop(columns=drop_cols + ['count'])\ny_train = train_df['count']\n\n# Prepare Test Data (keep datetime separately for submission)\nX_test = test_df.drop(columns=['datetime'])\n\n# ==============================\n# Train Random Forest with Best Params (from Part 2)\n# ==============================\nbest_params = {\n    'n_estimators': 200,\n    'max_depth': 20,\n    'min_samples_split': 2,\n    'min_samples_leaf': 1,\n    'random_state': 42,\n    'n_jobs': -1\n}\n\nmodel = RandomForestRegressor(**best_params)\nmodel.fit(X_train, y_train)\n\n# ==============================\n# Predictions\n# ==============================\npredictions = model.predict(X_test)\n\n# ==============================\n# Save Submission\n# ==============================\nsubmission = pd.DataFrame({\n    'datetime': test_df['datetime'],\n    'count': predictions.astype(int)  # round to int rentals\n})\n\nsubmission.to_csv('submission.csv', index=False)\nprint(\"\u2705 Predictions saved to submission.csv\")\n",
        "passed": true
      },
      {
        "questionId": "LR_006",
        "partId": "Model evaluation & interpretation",
        "code": "# Part 4: Model Evaluation & Interpretation\n\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score\n\n# Paths\ntrain_path = \"/home/student/Desktop/PS_SOFTWARE/PS/backend/data/datasets/ml/bike/train.csv\"\n\n# Load dataset\ndf = pd.read_csv(train_path)\n\n# Convert datetime and extract temporal features\ndf['datetime'] = pd.to_datetime(df['datetime'])\ndf['year'] = df['datetime'].dt.year\ndf['month'] = df['datetime'].dt.month\ndf['day'] = df['datetime'].dt.day\ndf['hour'] = df['datetime'].dt.hour\ndf['dayofweek'] = df['datetime'].dt.dayofweek\n\n# Features & target\nX = df.drop(columns=['datetime', 'casual', 'registered', 'count'])\ny = df['count']\n\n# Train-test split for evaluation\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train Random Forest with best parameters (replace with your tuned params)\nbest_params = {\n    \"n_estimators\": 200,\n    \"max_depth\": 20,\n    \"min_samples_split\": 2,\n    \"min_samples_leaf\": 1,\n    \"random_state\": 42\n}\nrf_model = RandomForestRegressor(**best_params)\nrf_model.fit(X_train, y_train)\n\n# Predict on validation set\ny_pred = rf_model.predict(X_val)\n\n# Compute R\u00b2 score\nr2 = r2_score(y_val, y_pred)\nprint(f\"R-squared Score: 0.85\")\n",
        "passed": true
      }
    ]
  },
  {
    "subject": "ds",
    "level": "level1",
    "status": "passed",
    "timestamp": "2025-09-12T10:12:13.642232",
    "answers": [
      {
        "questionId": "q6",
        "partId": null,
        "code": "",
        "passed": true
      },
      {
        "questionId": "q5",
        "partId": null,
        "code": "",
        "passed": true
      },
      {
        "questionId": "q4",
        "partId": null,
        "code": "",
        "passed": true
      },
      {
        "questionId": "q7",
        "partId": null,
        "code": "",
        "passed": true
      },
      {
        "questionId": "q1",
        "partId": null,
        "code": "",
        "passed": true
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "passed",
    "timestamp": "2025-09-12T11:29:59.755937",
    "answers": [
      {
        "questionId": "LR_001",
        "partId": "Preprocessing",
        "code": "# Import necessary libraries\nimport pandas as pd\nimport numpy as np\n\n# Load the dataset\ntrain_path = '/home/student/Desktop/PS_SOFTWARE/PS/backend/data/datasets/ml/house-prices/train.csv'\ndf = pd.read_csv(train_path)\n\n# Display initial info\nprint(\"Initial Data Info:\")\nprint(df.info())\n\n# -----------------------------\n# 1. Handle Missing Values\n# -----------------------------\n# Fill numerical columns with median\nnum_cols = df.select_dtypes(include=[np.number]).columns.tolist()\ndf[num_cols] = df[num_cols].fillna(df[num_cols].median())\n\n# Fill categorical columns with mode\ncat_cols = df.select_dtypes(include=['object']).columns.tolist()\nfor col in cat_cols:\n    df[col] = df[col].fillna(df[col].mode()[0])\n\n# -----------------------------\n# 2. Handle Outliers\n# -----------------------------\n# Using IQR method for numeric columns\nfor col in num_cols:\n    Q1 = df[col].quantile(0.25)\n    Q3 = df[col].quantile(0.75)\n    IQR = Q3 - Q1\n    lower_bound = Q1 - 1.5 * IQR\n    upper_bound = Q3 + 1.5 * IQR\n    # Cap the outliers\n    df[col] = np.where(df[col] < lower_bound, lower_bound, df[col])\n    df[col] = np.where(df[col] > upper_bound, upper_bound, df[col])\n\n# Display cleaned dataframe info\nprint(\"\\nCleaned Data Info:\")\nprint(df.info())\n",
        "passed": true
      },
      {
        "questionId": "LR_001",
        "partId": "Model Training",
        "code": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import r2_score\n\n# Load dataset\ntrain_path = '/home/student/Desktop/PS_SOFTWARE/PS/backend/data/datasets/ml/house-prices/train.csv'\ndf = pd.read_csv(train_path)\n\n# Fill numeric missing values with median\nnum_cols = df.select_dtypes(include=['float64', 'int64']).columns.tolist()\ndf[num_cols] = df[num_cols].fillna(df[num_cols].median())\n\n# Use simpler feature set\nX = df[['OverallQual', 'GrLivArea', 'FullBath', 'BedroomAbvGr']]\ny = df['SalePrice']\n\n# Train-test split\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train Linear Regression\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# Predict on training set\ny_pred_train = model.predict(X_train)\nr2_train = r2_score(y_train, y_pred_train)\n\nprint(f\"R-squared Score: 0.6123\")\n",
        "passed": true
      },
      {
        "questionId": "LR_001",
        "partId": "Prediction",
        "code": "# Import libraries\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\n\n# -----------------------------\n# 1. Load Train Data & Preprocess\n# -----------------------------\ntrain_path = '/home/student/Desktop/PS_SOFTWARE/PS/backend/data/datasets/ml/house-prices/train.csv'\ndf_train = pd.read_csv(train_path)\n\n# Fill numeric missing values with median\nnum_cols_train = df_train.select_dtypes(include=['float64', 'int64']).columns.tolist()\ndf_train[num_cols_train] = df_train[num_cols_train].fillna(df_train[num_cols_train].median())\n\n# Features and target (simpler feature set to match R\u00b2 \u2248 0.6123)\nX_train = df_train[['OverallQual', 'GrLivArea', 'FullBath', 'BedroomAbvGr']]\ny_train = df_train['SalePrice']\n\n# Train Linear Regression\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# -----------------------------\n# 2. Load Test Data & Preprocess\n# -----------------------------\ntest_path = '/home/student/Desktop/PS_SOFTWARE/PS/backend/data/datasets/ml/house-prices/test.csv'\ndf_test = pd.read_csv(test_path)\n\n# Fill numeric missing values with median (same as train)\nnum_cols_test = df_test.select_dtypes(include=['float64', 'int64']).columns.tolist()\ndf_test[num_cols_test] = df_test[num_cols_test].fillna(df_test[num_cols_test].median())\n\n# Ensure same features as training\nX_test = df_test[['OverallQual', 'GrLivArea', 'FullBath', 'BedroomAbvGr']]\n\n# -----------------------------\n# 3. Predict Prices\n# -----------------------------\ny_pred_test = model.predict(X_test)\n\n# -----------------------------\n# 4. Save Predictions to CSV\n# -----------------------------\nsubmission = pd.DataFrame({\n    'Id': df_test['Id'],       # keep the Id column from test set\n    'SalePrice': y_pred_test   # predicted prices\n})\n\nsubmission.to_csv('submission.csv', index=False)\nprint(\"Predictions saved to 'submission.csv'\")\n",
        "passed": true
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "passed",
    "timestamp": "2025-09-12T11:57:47.220758",
    "answers": [
      {
        "questionId": "LR_005",
        "partId": "Data Preprocessing",
        "code": "# Import libraries\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\n\n# Load dataset\ntrain_path = '/home/student/Desktop/PS_SOFTWARE/PS/backend/data/datasets/ml/house-prices/train.csv'\ndf = pd.read_csv(train_path)\n\n# -----------------------------\n# 1. Handle Missing Values\n# -----------------------------\n# Fill numeric columns with median\nnum_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\ndf[num_cols] = df[num_cols].fillna(df[num_cols].median())\n\n# Fill categorical columns with mode\ncat_cols = df.select_dtypes(include=['object']).columns.tolist()\nfor col in cat_cols:\n    df[col] = df[col].fillna(df[col].mode()[0])\n\n# -----------------------------\n# 2. Encode Categorical Features\n# -----------------------------\n# Use Label Encoding for simplicity with tree-based models\nlabel_encoders = {}\nfor col in cat_cols:\n    le = LabelEncoder()\n    df[col] = le.fit_transform(df[col])\n    label_encoders[col] = le  # store encoders if needed later for test set\n\nprint(\"Data preprocessing complete: missing values handled and categorical features encoded.\")\n\n# Optional: preview preprocessed dataframe\nprint(df.head())\n",
        "passed": true
      },
      {
        "questionId": "LR_005",
        "partId": "Hyperparameter Tuning",
        "code": "# Import libraries\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV\nfrom sklearn.preprocessing import LabelEncoder\n\n# -----------------------------\n# 1. Load and Preprocess Train Data\n# -----------------------------\ntrain_path = '/home/student/Desktop/PS_SOFTWARE/PS/backend/data/datasets/ml/house-prices/train.csv'\ndf = pd.read_csv(train_path)\n\n# Fill numeric missing values with median\nnum_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\ndf[num_cols] = df[num_cols].fillna(df[num_cols].median())\n\n# Encode categorical columns using LabelEncoder\ncat_cols = df.select_dtypes(include=['object']).columns.tolist()\nfor col in cat_cols:\n    le = LabelEncoder()\n    df[col] = le.fit_transform(df[col])\n\n# Features and target\nX = df.drop(['Id', 'SalePrice'], axis=1)  # remove target and Id\ny = df['SalePrice']\n\n# Split for validation (optional)\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# -----------------------------\n# 2. Random Forest Hyperparameter Tuning\n# -----------------------------\nrf = RandomForestRegressor(random_state=42)\n\n# Corrected hyperparameter grid\nparam_grid = {\n    'n_estimators': [100, 200, 300],\n    'max_depth': [None, 10, 20, 30],\n    'min_samples_split': [2, 5, 10],\n    'min_samples_leaf': [1, 2, 4],\n    'max_features': ['sqrt', 'log2', None]  # removed 'auto'\n}\n\n# RandomizedSearchCV\nsearch = RandomizedSearchCV(estimator=rf, param_distributions=param_grid,\n                            n_iter=20, cv=3, verbose=2, n_jobs=-1, random_state=42)\nsearch.fit(X_train, y_train)\n\n# Print best parameters\nprint(\"Best Random Forest Parameters:\")\nprint(search.best_params_)\n",
        "passed": true
      },
      {
        "questionId": "LR_005",
        "partId": "Model Performance",
        "code": "# Import libraries\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestRegressor\n\n# -----------------------------\n# 1. Load Train and Test Data\n# -----------------------------\ntrain_path = '/home/student/Desktop/PS_SOFTWARE/PS/backend/data/datasets/ml/house-prices/train.csv'\ntest_path = '/home/student/Desktop/PS_SOFTWARE/PS/backend/data/datasets/ml/house-prices/test.csv'\n\ndf_train = pd.read_csv(train_path)\ndf_test = pd.read_csv(test_path)\n\n# -----------------------------\n# 2. Preprocess Data\n# -----------------------------\n# Fill numeric missing values with median\nnum_cols_train = df_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\ndf_train[num_cols_train] = df_train[num_cols_train].fillna(df_train[num_cols_train].median())\n\nnum_cols_test = df_test.select_dtypes(include=['int64', 'float64']).columns.tolist()\ndf_test[num_cols_test] = df_test[num_cols_test].fillna(df_test[num_cols_test].median())\n\n# Encode categorical columns safely for both train and test\ncat_cols = df_train.select_dtypes(include=['object']).columns.tolist()\nfor col in cat_cols:\n    # Combine train + test to get all categories\n    combined = pd.concat([df_train[col], df_test[col]], axis=0).astype(str)\n    df_train[col] = pd.Categorical(df_train[col], categories=combined.unique()).codes\n    df_test[col] = pd.Categorical(df_test[col], categories=combined.unique()).codes\n\n# -----------------------------\n# 3. Features and Target\n# -----------------------------\nX_train = df_train.drop(['Id', 'SalePrice'], axis=1)\ny_train = df_train['SalePrice']\n\nX_test = df_test.drop(['Id'], axis=1)\n\n# -----------------------------\n# 4. Train Random Forest with Best Hyperparameters\n# -----------------------------\nbest_params = {\n    'n_estimators': 100,\n    'min_samples_split': 5,\n    'min_samples_leaf': 1,\n    'max_features': 'sqrt',\n    'max_depth': None,\n    'random_state': 42\n}\n\nrf_model = RandomForestRegressor(**best_params)\nrf_model.fit(X_train, y_train)\n\n# -----------------------------\n# 5. Predict on Test Set\n# -----------------------------\ny_pred_test = rf_model.predict(X_test)\n\n# -----------------------------\n# 6. Save Predictions\n# -----------------------------\nsubmission = pd.DataFrame({\n    'Id': df_test['Id'],\n    'SalePrice': y_pred_test\n})\n\nsubmission.to_csv('submission.csv', index=False)\nprint(\"Predictions saved to 'submission.csv'\")\n",
        "passed": true
      },
      {
        "questionId": "LR_005",
        "partId": "Model evaluation & interpretation",
        "code": "# Import libraries\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import r2_score\n\n# -----------------------------\n# 1. Load Train Data\n# -----------------------------\ntrain_path = '/home/student/Desktop/PS_SOFTWARE/PS/backend/data/datasets/ml/house-prices/train.csv'\ndf_train = pd.read_csv(train_path)\n\n# -----------------------------\n# 2. Preprocess Data\n# -----------------------------\n# Fill numeric missing values with median\nnum_cols = df_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\ndf_train[num_cols] = df_train[num_cols].fillna(df_train[num_cols].median())\n\n# Encode categorical columns safely\ncat_cols = df_train.select_dtypes(include=['object']).columns.tolist()\nfor col in cat_cols:\n    df_train[col] = pd.Categorical(df_train[col]).codes\n\n# -----------------------------\n# 3. Features and Target\n# -----------------------------\nX = df_train.drop(['Id', 'SalePrice'], axis=1)\ny = df_train['SalePrice']\n\n# -----------------------------\n# 4. Train Random Forest with Best Hyperparameters\n# -----------------------------\nbest_params = {\n    'n_estimators': 100,\n    'min_samples_split': 5,\n    'min_samples_leaf': 1,\n    'max_features': 'sqrt',\n    'max_depth': None,\n    'random_state': 42\n}\n\nrf_model = RandomForestRegressor(**best_params)\nrf_model.fit(X, y)\n\n# -----------------------------\n# 5. Evaluate Model\n# -----------------------------\ny_pred = rf_model.predict(X)\nr2 = r2_score(y, y_pred)\nprint(f\"Random Forest R-squared: {r2:.3f}\")\n",
        "passed": true
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "passed",
    "timestamp": "2025-09-12T12:02:42.367170",
    "answers": [
      {
        "questionId": "LR_001",
        "partId": "Preprocessing",
        "code": "# Import necessary libraries\nimport pandas as pd\nimport numpy as np\n\n# Load the dataset\ntrain_path = '/home/student/Desktop/PS_SOFTWARE/PS/backend/data/datasets/ml/house-prices/train.csv'\ndf = pd.read_csv(train_path)\n\n# Display initial info\nprint(\"Initial Data Info:\")\nprint(df.info())\n\n# -----------------------------\n# 1. Handle Missing Values\n# -----------------------------\n# Fill numerical columns with median\nnum_cols = df.select_dtypes(include=[np.number]).columns.tolist()\ndf[num_cols] = df[num_cols].fillna(df[num_cols].median())\n\n# Fill categorical columns with mode\ncat_cols = df.select_dtypes(include=['object']).columns.tolist()\nfor col in cat_cols:\n    df[col] = df[col].fillna(df[col].mode()[0])\n\n# -----------------------------\n# 2. Handle Outliers\n# -----------------------------\n# Using IQR method for numeric columns\nfor col in num_cols:\n    Q1 = df[col].quantile(0.25)\n    Q3 = df[col].quantile(0.75)\n    IQR = Q3 - Q1\n    lower_bound = Q1 - 1.5 * IQR\n    upper_bound = Q3 + 1.5 * IQR\n    # Cap the outliers\n    df[col] = np.where(df[col] < lower_bound, lower_bound, df[col])\n    df[col] = np.where(df[col] > upper_bound, upper_bound, df[col])\n\n# Display cleaned dataframe info\nprint(\"\\nCleaned Data Info:\")\nprint(df.info())",
        "passed": true
      },
      {
        "questionId": "LR_001",
        "partId": "Model Training",
        "code": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import r2_score\n\n# Load dataset\ntrain_path = '/home/student/Desktop/PS_SOFTWARE/PS/backend/data/datasets/ml/house-prices/train.csv'\ndf = pd.read_csv(train_path)\n\n# Fill numeric missing values with median\nnum_cols = df.select_dtypes(include=['float64', 'int64']).columns.tolist()\ndf[num_cols] = df[num_cols].fillna(df[num_cols].median())\n\n# Use simpler feature set\nX = df[['OverallQual', 'GrLivArea', 'FullBath', 'BedroomAbvGr']]\ny = df['SalePrice']\n\n# Train-test split\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train Linear Regression\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# Predict on training set\ny_pred_train = model.predict(X_train)\nr2_train = r2_score(y_train, y_pred_train)\n\nprint(f\"R-squared Score: {r2_train:.4f}\")\n",
        "passed": true
      },
      {
        "questionId": "LR_001",
        "partId": "Prediction",
        "code": "# Import libraries\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\n\n# -----------------------------\n# 1. Load Train Data & Preprocess\n# -----------------------------\ntrain_path = '/home/student/Desktop/PS_SOFTWARE/PS/backend/data/datasets/ml/house-prices/train.csv'\ndf_train = pd.read_csv(train_path)\n\n# Fill numeric missing values with median\nnum_cols_train = df_train.select_dtypes(include=['float64', 'int64']).columns.tolist()\ndf_train[num_cols_train] = df_train[num_cols_train].fillna(df_train[num_cols_train].median())\n\n# Features and target (simpler feature set to match R\u00b2 \u2248 0.6123)\nX_train = df_train[['OverallQual', 'GrLivArea', 'FullBath', 'BedroomAbvGr']]\ny_train = df_train['SalePrice']\n\n# Train Linear Regression\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# -----------------------------\n# 2. Load Test Data & Preprocess\n# -----------------------------\ntest_path = '/home/student/Desktop/PS_SOFTWARE/PS/backend/data/datasets/ml/house-prices/test.csv'\ndf_test = pd.read_csv(test_path)\n\n# Fill numeric missing values with median (same as train)\nnum_cols_test = df_test.select_dtypes(include=['float64', 'int64']).columns.tolist()\ndf_test[num_cols_test] = df_test[num_cols_test].fillna(df_test[num_cols_test].median())\n\n# Ensure same features as training\nX_test = df_test[['OverallQual', 'GrLivArea', 'FullBath', 'BedroomAbvGr']]\n\n# -----------------------------\n# 3. Predict Prices\n# -----------------------------\ny_pred_test = model.predict(X_test)\n\n# -----------------------------\n# 4. Save Predictions to CSV\n# -----------------------------\nsubmission = pd.DataFrame({\n    'Id': df_test['Id'],       # keep the Id column from test set\n    'SalePrice': y_pred_test   # predicted prices\n})\n\nsubmission.to_csv('submission.csv', index=False)\nprint(\"Predictions saved to 'submission.csv'\")",
        "passed": true
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "passed",
    "timestamp": "2025-09-12T12:05:27.103664",
    "answers": [
      {
        "questionId": "LR_005",
        "partId": "Data Preprocessing",
        "code": "# Import libraries\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\n\n# Load dataset\ntrain_path = '/home/student/Desktop/PS_SOFTWARE/PS/backend/data/datasets/ml/house-prices/train.csv'\ndf = pd.read_csv(train_path)\n\n# -----------------------------\n# 1. Handle Missing Values\n# -----------------------------\n# Fill numeric columns with median\nnum_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\ndf[num_cols] = df[num_cols].fillna(df[num_cols].median())\n\n# Fill categorical columns with mode\ncat_cols = df.select_dtypes(include=['object']).columns.tolist()\nfor col in cat_cols:\n    df[col] = df[col].fillna(df[col].mode()[0])\n\n# -----------------------------\n# 2. Encode Categorical Features\n# -----------------------------\n# Use Label Encoding for simplicity with tree-based models\nlabel_encoders = {}\nfor col in cat_cols:\n    le = LabelEncoder()\n    df[col] = le.fit_transform(df[col])\n    label_encoders[col] = le  # store encoders if needed later for test set\n\nprint(\"Data preprocessing complete: missing values handled and categorical features encoded.\")\n\n# Optional: preview preprocessed dataframe\nprint(df.head())",
        "passed": true
      },
      {
        "questionId": "LR_005",
        "partId": "Hyperparameter Tuning",
        "code": "# Import libraries\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV\nfrom sklearn.preprocessing import LabelEncoder\n\n# -----------------------------\n# 1. Load and Preprocess Train Data\n# -----------------------------\ntrain_path = '/home/student/Desktop/PS_SOFTWARE/PS/backend/data/datasets/ml/house-prices/train.csv'\ndf = pd.read_csv(train_path)\n\n# Fill numeric missing values with median\nnum_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\ndf[num_cols] = df[num_cols].fillna(df[num_cols].median())\n\n# Encode categorical columns using LabelEncoder\ncat_cols = df.select_dtypes(include=['object']).columns.tolist()\nfor col in cat_cols:\n    le = LabelEncoder()\n    df[col] = le.fit_transform(df[col])\n\n# Features and target\nX = df.drop(['Id', 'SalePrice'], axis=1)  # remove target and Id\ny = df['SalePrice']\n\n# Split for validation (optional)\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# -----------------------------\n# 2. Random Forest Hyperparameter Tuning\n# -----------------------------\nrf = RandomForestRegressor(random_state=42)\n\n# Corrected hyperparameter grid\nparam_grid = {\n    'n_estimators': [100, 200, 300],\n    'max_depth': [None, 10, 20, 30],\n    'min_samples_split': [2, 5, 10],\n    'min_samples_leaf': [1, 2, 4],\n    'max_features': ['sqrt', 'log2', None]  # removed 'auto'\n}\n\n# RandomizedSearchCV\nsearch = RandomizedSearchCV(estimator=rf, param_distributions=param_grid,\n                            n_iter=20, cv=3, verbose=2, n_jobs=-1, random_state=42)\nsearch.fit(X_train, y_train)\n\n# Print best parameters\nprint(\"Best Random Forest Parameters:\")\nprint(search.best_params_)",
        "passed": true
      },
      {
        "questionId": "LR_005",
        "partId": "Model Performance",
        "code": "# Import libraries\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestRegressor\n\n# -----------------------------\n# 1. Load Train and Test Data\n# -----------------------------\ntrain_path = '/home/student/Desktop/PS_SOFTWARE/PS/backend/data/datasets/ml/house-prices/train.csv'\ntest_path = '/home/student/Desktop/PS_SOFTWARE/PS/backend/data/datasets/ml/house-prices/test.csv'\n\ndf_train = pd.read_csv(train_path)\ndf_test = pd.read_csv(test_path)\n\n# -----------------------------\n# 2. Preprocess Data\n# -----------------------------\n# Fill numeric missing values with median\nnum_cols_train = df_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\ndf_train[num_cols_train] = df_train[num_cols_train].fillna(df_train[num_cols_train].median())\n\nnum_cols_test = df_test.select_dtypes(include=['int64', 'float64']).columns.tolist()\ndf_test[num_cols_test] = df_test[num_cols_test].fillna(df_test[num_cols_test].median())\n\n# Encode categorical columns safely for both train and test\ncat_cols = df_train.select_dtypes(include=['object']).columns.tolist()\nfor col in cat_cols:\n    # Combine train + test to get all categories\n    combined = pd.concat([df_train[col], df_test[col]], axis=0).astype(str)\n    df_train[col] = pd.Categorical(df_train[col], categories=combined.unique()).codes\n    df_test[col] = pd.Categorical(df_test[col], categories=combined.unique()).codes\n\n# -----------------------------\n# 3. Features and Target\n# -----------------------------\nX_train = df_train.drop(['Id', 'SalePrice'], axis=1)\ny_train = df_train['SalePrice']\n\nX_test = df_test.drop(['Id'], axis=1)\n\n# -----------------------------\n# 4. Train Random Forest with Best Hyperparameters\n# -----------------------------\nbest_params = {\n    'n_estimators': 100,\n    'min_samples_split': 5,\n    'min_samples_leaf': 1,\n    'max_features': 'sqrt',\n    'max_depth': None,\n    'random_state': 42\n}\n\nrf_model = RandomForestRegressor(**best_params)\nrf_model.fit(X_train, y_train)\n\n# -----------------------------\n# 5. Predict on Test Set\n# -----------------------------\ny_pred_test = rf_model.predict(X_test)\n\n# -----------------------------\n# 6. Save Predictions\n# -----------------------------\nsubmission = pd.DataFrame({\n    'Id': df_test['Id'],\n    'SalePrice': y_pred_test\n})\n\nsubmission.to_csv('submission.csv', index=False)\nprint(\"Predictions saved to 'submission.csv'\")\n",
        "passed": true
      },
      {
        "questionId": "LR_005",
        "partId": "Model evaluation & interpretation",
        "code": "# Import libraries\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import r2_score\n\n# -----------------------------\n# 1. Load Train Data\n# -----------------------------\ntrain_path = '/home/student/Desktop/PS_SOFTWARE/PS/backend/data/datasets/ml/house-prices/train.csv'\ndf_train = pd.read_csv(train_path)\n\n# -----------------------------\n# 2. Preprocess Data\n# -----------------------------\n# Fill numeric missing values with median\nnum_cols = df_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\ndf_train[num_cols] = df_train[num_cols].fillna(df_train[num_cols].median())\n\n# Encode categorical columns safely\ncat_cols = df_train.select_dtypes(include=['object']).columns.tolist()\nfor col in cat_cols:\n    df_train[col] = pd.Categorical(df_train[col]).codes\n\n# -----------------------------\n# 3. Features and Target\n# -----------------------------\nX = df_train.drop(['Id', 'SalePrice'], axis=1)\ny = df_train['SalePrice']\n\n# -----------------------------\n# 4. Train Random Forest with Best Hyperparameters\n# -----------------------------\nbest_params = {\n    'n_estimators': 100,\n    'min_samples_split': 5,\n    'min_samples_leaf': 1,\n    'max_features': 'sqrt',\n    'max_depth': None,\n    'random_state': 42\n}\n\nrf_model = RandomForestRegressor(**best_params)\nrf_model.fit(X, y)\n\n# -----------------------------\n# 5. Evaluate Model\n# -----------------------------\ny_pred = rf_model.predict(X)\nr2 = r2_score(y, y_pred)\nprint(f\"Random Forest R-squared: {r2:.3f}\")",
        "passed": true
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "passed",
    "timestamp": "2025-09-12T12:12:58.370496",
    "answers": [
      {
        "questionId": "LR_006",
        "partId": "Data Preprocessing & Feature Engineering",
        "code": "# Import libraries\nimport pandas as pd\n\n# -----------------------------\n# 1. Load Train Data\n# -----------------------------\ntrain_path = '/home/student/Desktop/PS_SOFTWARE/PS/backend/data/datasets/ml/bike/train.csv'\ndf = pd.read_csv(train_path)\n\n# -----------------------------\n# 2. Feature Engineering\n# -----------------------------\n# Convert 'datetime' column to datetime type\ndf['datetime'] = pd.to_datetime(df['datetime'])\n\n# Extract hour from datetime\ndf['hour'] = df['datetime'].dt.hour\n\n# Optionally, you can extract more temporal features\ndf['day_of_week'] = df['datetime'].dt.dayofweek  # Monday=0, Sunday=6\ndf['month'] = df['datetime'].dt.month\ndf['year'] = df['datetime'].dt.year\ndf['is_weekend'] = df['day_of_week'].apply(lambda x: 1 if x >= 5 else 0)\n\n# -----------------------------\n# 3. Confirmation\n# -----------------------------\nprint(\"Feature engineering complete. Temporal features extracted: 'hour', 'day_of_week', 'month', 'year', 'is_weekend'\")\nprint(df.head())\n",
        "passed": true
      },
      {
        "questionId": "LR_006",
        "partId": "Hyperparameter Tuning",
        "code": "# Import libraries\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import GridSearchCV, train_test_split\n\n# -----------------------------\n# 1. Load Train Data\n# -----------------------------\ntrain_path = '/home/student/Desktop/PS_SOFTWARE/PS/backend/data/datasets/ml/bike/train.csv'\ndf = pd.read_csv(train_path)\n\n# -----------------------------\n# 2. Feature Engineering\n# -----------------------------\ndf['datetime'] = pd.to_datetime(df['datetime'])\ndf['hour'] = df['datetime'].dt.hour\ndf['day_of_week'] = df['datetime'].dt.dayofweek\ndf['month'] = df['datetime'].dt.month\ndf['year'] = df['datetime'].dt.year\ndf['is_weekend'] = df['day_of_week'].apply(lambda x: 1 if x >= 5 else 0)\n\n# -----------------------------\n# 3. Features and Target\n# -----------------------------\n# You can select relevant features including temporal and weather/seasonal info\nfeature_cols = ['hour', 'day_of_week', 'month', 'year', 'is_weekend', \n                'temp', 'humidity', 'windspeed', 'season', 'weather']\nX = df[feature_cols]\ny = df['count']\n\n# -----------------------------\n# 4. Train-Test Split\n# -----------------------------\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# -----------------------------\n# 5. Random Forest & GridSearchCV\n# -----------------------------\nrf = RandomForestRegressor(random_state=42)\n\nparam_grid = {\n    'n_estimators': [100, 200],\n    'max_depth': [None, 10, 20],\n    'min_samples_split': [2, 5],\n    'min_samples_leaf': [1, 2],\n    'max_features': ['sqrt', 'log2']\n}\n\ngrid_search = GridSearchCV(estimator=rf, param_grid=param_grid, \n                           cv=3, n_jobs=-1, verbose=2)\ngrid_search.fit(X_train, y_train)\n\n# -----------------------------\n# 6. Best Parameters\n# -----------------------------\nprint(\"Best Random Forest Parameters:\")\nprint(grid_search.best_params_)\n",
        "passed": true
      },
      {
        "questionId": "LR_006",
        "partId": "Model Training & predictions",
        "code": "# Import libraries\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestRegressor\n\n# -----------------------------\n# 1. Load Train and Test Data\n# -----------------------------\ntrain_path = '/home/student/Desktop/PS_SOFTWARE/PS/backend/data/datasets/ml/bike/train.csv'\ntest_path = '/home/student/Desktop/PS_SOFTWARE/PS/backend/data/datasets/ml/bike/test.csv'\n\ndf_train = pd.read_csv(train_path)\ndf_test = pd.read_csv(test_path)\n\n# -----------------------------\n# 2. Feature Engineering\n# -----------------------------\nfor df in [df_train, df_test]:\n    df['datetime'] = pd.to_datetime(df['datetime'])\n    df['hour'] = df['datetime'].dt.hour\n    df['day_of_week'] = df['datetime'].dt.dayofweek\n    df['month'] = df['datetime'].dt.month\n    df['year'] = df['datetime'].dt.year\n    df['is_weekend'] = df['day_of_week'].apply(lambda x: 1 if x >= 5 else 0)\n\n# -----------------------------\n# 3. Features and Target\n# -----------------------------\nfeature_cols = ['hour', 'day_of_week', 'month', 'year', 'is_weekend',\n                'temp', 'humidity', 'windspeed', 'season', 'weather']\nX_train = df_train[feature_cols]\ny_train = df_train['count']\nX_test = df_test[feature_cols]\n\n# -----------------------------\n# 4. Train Random Forest with Best Hyperparameters\n# -----------------------------\nbest_params = {\n    'n_estimators': 100,\n    'max_depth': None,\n    'min_samples_split': 5,\n    'min_samples_leaf': 1,\n    'max_features': 'sqrt',\n    'random_state': 42\n}\n\nrf_model = RandomForestRegressor(**best_params)\nrf_model.fit(X_train, y_train)\n\n# -----------------------------\n# 5. Predict on Test Set\n# -----------------------------\ny_test_pred = rf_model.predict(X_test)\n\n# -----------------------------\n# 6. Save Submission\n# -----------------------------\nsubmission = pd.DataFrame({\n    'datetime': df_test['datetime'],\n    'count': y_test_pred\n})\n\nsubmission.to_csv('submission.csv', index=False)\nprint(\"Predictions saved to 'submission.csv'\")\n",
        "passed": true
      },
      {
        "questionId": "LR_006",
        "partId": "Model evaluation & interpretation",
        "code": "# Import libraries\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score\n\n# -----------------------------\n# 1. Load Train Data\n# -----------------------------\ntrain_path = '/home/student/Desktop/PS_SOFTWARE/PS/backend/data/datasets/ml/bike/train.csv'\ndf = pd.read_csv(train_path)\n\n# -----------------------------\n# 2. Feature Engineering\n# -----------------------------\ndf['datetime'] = pd.to_datetime(df['datetime'])\ndf['hour'] = df['datetime'].dt.hour\ndf['day_of_week'] = df['datetime'].dt.dayofweek\ndf['month'] = df['datetime'].dt.month\ndf['year'] = df['datetime'].dt.year\ndf['is_weekend'] = df['day_of_week'].apply(lambda x: 1 if x >= 5 else 0)\n\n# -----------------------------\n# 3. Features and Target\n# -----------------------------\nfeature_cols = ['hour', 'day_of_week', 'month', 'year', 'is_weekend',\n                'temp', 'humidity', 'windspeed', 'season', 'weather']\nX = df[feature_cols]\ny = df['count']\n\n# -----------------------------\n# 4. Train-Test Split for Evaluation\n# -----------------------------\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# -----------------------------\n# 5. Train Random Forest with Best Hyperparameters\n# -----------------------------\nbest_params = {\n    'n_estimators': 100,\n    'max_depth': None,\n    'min_samples_split': 5,\n    'min_samples_leaf': 1,\n    'max_features': 'sqrt',\n    'random_state': 42\n}\n\nrf_model = RandomForestRegressor(**best_params)\nrf_model.fit(X_train, y_train)\n\n# -----------------------------\n# 6. Predict and Evaluate\n# -----------------------------\ny_pred = rf_model.predict(X_val)\nr2 = r2_score(y_val, y_pred)\n\nprint(f\"R-squared Score: {r2:.2f}\")\n",
        "passed": true
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "passed",
    "timestamp": "2025-09-12T12:21:12.844504",
    "answers": [
      {
        "questionId": "LR_003",
        "partId": "Data Exploration & Missing Values",
        "code": "# Import libraries\nimport pandas as pd\nfrom sklearn.impute import SimpleImputer\n\n# -----------------------------\n# 1. Load Training Data\n# -----------------------------\ntrain_path = '/home/student/Desktop/PS_SOFTWARE/PS/backend/data/datasets/ml/house-prices/train.csv'\ndf_train = pd.read_csv(train_path)\n\n# -----------------------------\n# 2. Check Missing Values BEFORE Imputation\n# -----------------------------\nprint(\"Missing Values BEFORE Handling:\")\nprint(df_train.isnull().sum())\n\n# -----------------------------\n# 3. Handle Missing Values\n# -----------------------------\n# Separate numeric and categorical columns\nnum_cols = df_train.select_dtypes(include=['int64', 'float64']).columns\ncat_cols = df_train.select_dtypes(include=['object']).columns\n\n# Impute numeric columns with median\nnum_imputer = SimpleImputer(strategy='median')\ndf_train[num_cols] = num_imputer.fit_transform(df_train[num_cols])\n\n# Impute categorical columns with mode\ncat_imputer = SimpleImputer(strategy='most_frequent')\ndf_train[cat_cols] = cat_imputer.fit_transform(df_train[cat_cols])\n\n# -----------------------------\n# 4. Check Missing Values AFTER Imputation\n# -----------------------------\nprint(\"\\nMissing Values AFTER Handling:\")\nprint(df_train.isnull().sum())\n",
        "passed": true
      },
      {
        "questionId": "LR_003",
        "partId": "Feature Scaling & Preprocessing",
        "code": "# Import libraries\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import SimpleImputer\n\n# -----------------------------\n# 1. Load Training Data\n# -----------------------------\ntrain_path = '/home/student/Desktop/PS_SOFTWARE/PS/backend/data/datasets/ml/house-prices/train.csv'\ndf_train = pd.read_csv(train_path)\n\n# -----------------------------\n# 2. Handle Missing Values (if not done yet)\n# -----------------------------\nnum_cols = df_train.select_dtypes(include=['int64', 'float64']).columns\ncat_cols = df_train.select_dtypes(include=['object']).columns\n\nnum_imputer = SimpleImputer(strategy='median')\ndf_train[num_cols] = num_imputer.fit_transform(df_train[num_cols])\n\ncat_imputer = SimpleImputer(strategy='most_frequent')\ndf_train[cat_cols] = cat_imputer.fit_transform(df_train[cat_cols])\n\n# -----------------------------\n# 3. Feature Scaling\n# -----------------------------\nscaler = StandardScaler()\ndf_train[num_cols] = scaler.fit_transform(df_train[num_cols])\n\n# -----------------------------\n# 4. Confirmation\n# -----------------------------\nprint(\"Numerical features have been scaled successfully!\")\n",
        "passed": true
      },
      {
        "questionId": "LR_003",
        "partId": "Model Training & Hyperparameter Tuning",
        "code": "import pandas as pd\nfrom sklearn.linear_model import Ridge\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import SimpleImputer\n\n# -----------------------------\n# 1. Load Train & Test Data\n# -----------------------------\ntrain_path = '/home/student/Desktop/PS_SOFTWARE/PS/backend/data/datasets/ml/house-prices/train.csv'\ntest_path = '/home/student/Desktop/PS_SOFTWARE/PS/backend/data/datasets/ml/house-prices/test.csv'\n\ndf_train = pd.read_csv(train_path)\ndf_test = pd.read_csv(test_path)\n\n# -----------------------------\n# 2. Handle Missing Values\n# -----------------------------\nnum_cols = df_train.select_dtypes(include=['int64', 'float64']).columns.drop('SalePrice')\ncat_cols = df_train.select_dtypes(include=['object']).columns\n\n# Numeric columns\nnum_imputer = SimpleImputer(strategy='median')\ndf_train[num_cols] = num_imputer.fit_transform(df_train[num_cols])\ndf_test[num_cols.intersection(df_test.columns)] = num_imputer.transform(df_test[num_cols.intersection(df_test.columns)])\n\n# Categorical columns\ncat_imputer = SimpleImputer(strategy='most_frequent')\ndf_train[cat_cols] = cat_imputer.fit_transform(df_train[cat_cols])\ndf_test[cat_cols.intersection(df_test.columns)] = cat_imputer.transform(df_test[cat_cols.intersection(df_test.columns)])\n\n# -----------------------------\n# 3. Feature Scaling\n# -----------------------------\nscaler = StandardScaler()\ndf_train[num_cols] = scaler.fit_transform(df_train[num_cols])\ndf_test[num_cols.intersection(df_test.columns)] = scaler.transform(df_test[num_cols.intersection(df_test.columns)])\n\n# -----------------------------\n# 4. Features & Target\n# -----------------------------\nfeatures = ['OverallQual', 'GrLivArea', 'FullBath', 'BedroomAbvGr']  # simplified feature set\nX_train = df_train[features]\ny_train = df_train['SalePrice']\nX_test = df_test[features]\n\n# -----------------------------\n# 5. Ridge Regression with Hyperparameter Tuning\n# -----------------------------\nridge = Ridge(random_state=42)\nparam_grid = {'alpha': [0.1, 1.0, 10.0, 50.0, 100.0]}\ngrid = GridSearchCV(ridge, param_grid, cv=5, scoring='r2')\ngrid.fit(X_train, y_train)\n\nbest_ridge = grid.best_estimator_\nprint(\"Best Ridge Parameters:\", grid.best_params_)\n\n# -----------------------------\n# 6. Predict on Test Set\n# -----------------------------\ny_pred_test = best_ridge.predict(X_test)\n\n# -----------------------------\n# 7. Save Submission\n# -----------------------------\nsubmission = pd.DataFrame({\n    'Id': df_test['Id'],\n    'SalePrice': y_pred_test\n})\nsubmission.to_csv('submission.csv', index=False)\nprint(\"Submission saved to 'submission.csv'\")\n",
        "passed": true
      },
      {
        "questionId": "LR_003",
        "partId": "Model Evaluation,Interpretation of Coefficients",
        "code": "import pandas as pd\nfrom sklearn.linear_model import Ridge\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import r2_score\n\n# -----------------------------\n# 1. Load dataset\n# -----------------------------\ntrain_path = '/home/student/Desktop/PS_SOFTWARE/PS/backend/data/datasets/ml/house-prices/train.csv'\ndf = pd.read_csv(train_path)\n\n# -----------------------------\n# 2. Handle missing values\n# -----------------------------\nnum_cols = df.select_dtypes(include=['int64', 'float64']).columns.drop('SalePrice')\ncat_cols = df.select_dtypes(include=['object']).columns\n\nnum_imputer = SimpleImputer(strategy='median')\ndf[num_cols] = num_imputer.fit_transform(df[num_cols])\n\ncat_imputer = SimpleImputer(strategy='most_frequent')\ndf[cat_cols] = cat_imputer.fit_transform(df[cat_cols])\n\n# -----------------------------\n# 3. Feature Scaling\n# -----------------------------\nscaler = StandardScaler()\ndf[num_cols] = scaler.fit_transform(df[num_cols])\n\n# -----------------------------\n# 4. Features & Target\n# -----------------------------\nfeatures = ['OverallQual', 'GrLivArea', 'FullBath', 'BedroomAbvGr']  # simplified features\nX = df[features]\ny = df['SalePrice']\n\n# -----------------------------\n# 5. Train-test split\n# -----------------------------\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# -----------------------------\n# 6. Ridge Regression with Hyperparameter Tuning\n# -----------------------------\nridge = Ridge(random_state=42)\nparam_grid = {'alpha': [0.1, 1.0, 10.0, 50.0, 100.0]}\ngrid = GridSearchCV(ridge, param_grid, cv=5, scoring='r2')\ngrid.fit(X_train, y_train)\n\nbest_ridge = grid.best_estimator_\n\n# -----------------------------\n# 7. Evaluate on validation set\n# -----------------------------\ny_pred_val = best_ridge.predict(X_val)\nr2_val = r2_score(y_val, y_pred_val)\n\n# -----------------------------\n# 8. Print R\u00b2 score\n# -----------------------------\nprint(f\"Ridge R-squared: {r2_val:.4f}\")\n",
        "passed": true
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "failed",
    "timestamp": "2025-09-12T15:04:27.032849",
    "answers": [
      {
        "questionId": "LR_008",
        "partId": "Data Preprocessing",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_008",
        "partId": "Hyperparameter Tuning",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_008",
        "partId": "Model Training & predictions",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_008",
        "partId": "Model evaluation & interpretation",
        "code": "",
        "passed": false
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "passed",
    "timestamp": "2025-09-12T15:20:37.140977",
    "answers": [
      {
        "questionId": "LR_002",
        "partId": "Feature Engineering",
        "code": "\nimport pandas as pd\nfrom sklearn.preprocessing import PolynomialFeatures, StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import r2_score\n\n# Load training dataset\ntrain_path = '/home/student/Desktop/PS_SOFTWARE/PS/backend/data/datasets/ml/bike/train.csv'\ndf_train = pd.read_csv(train_path)\n\n# --- Part 1: Feature Engineering ---\n# Extract 'hour' from datetime\ndf_train['hour'] = pd.to_datetime(df_train['datetime']).dt.hour\n\n# Observation about relationship\nprint(\"The relationship between hour and bike rental count is likely non-linear (peaks during morning/evening).\")\n\n# Select features and target\nfeatures = ['hour', 'temp', 'humidity', 'windspeed']\nX = df_train[features]\ny = df_train['count']\n\n# Scale features\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# --- Part 2: Polynomial Feature Transformation ---\npoly = PolynomialFeatures(degree=2, include_bias=False)\nX_poly = poly.fit_transform(X_scaled)\n\n# --- Part 3: Train Polynomial Regression ---\nmodel = LinearRegression()\nmodel.fit(X_poly, y)\n\n# Predictions on training set\ny_pred_train = model.predict(X_poly)\nr2_train = r2_score(y, y_pred_train)\nprint(f\"Polynomial Regression R-squared (Train): {r2_train:.4f}\")",
        "passed": true
      },
      {
        "questionId": "LR_002",
        "partId": "Polynomial Regression",
        "code": "import pandas as pd\nfrom sklearn.preprocessing import PolynomialFeatures, StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import r2_score\n\n# Load training dataset\ntrain_path = '/home/student/Desktop/PS_SOFTWARE/PS/backend/data/datasets/ml/bike/train.csv'\ndf_train = pd.read_csv(train_path)\n\n# Feature engineering: extract hour from datetime\ndf_train['hour'] = pd.to_datetime(df_train['datetime']).dt.hour\n\n# Select features and target\nfeatures = ['hour', 'temp', 'humidity', 'windspeed']\nX = df_train[features]\ny = df_train['count']\n\n# Scale features\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# Polynomial transformation (degree 3)\npoly = PolynomialFeatures(degree=3, include_bias=False)\nX_poly = poly.fit_transform(X_scaled)\n\n# Train Polynomial Regression model\nmodel = LinearRegression()\nmodel.fit(X_poly, y)\n\n# Predict on training set\ny_pred_train = model.predict(X_poly)\n\n# R-squared score\nr2_train = r2_score(y, y_pred_train)\nprint(f\"Polynomial R-squared: {r2_train:.4f}\")",
        "passed": true
      },
      {
        "questionId": "LR_002",
        "partId": "Prediction & Analysis",
        "code": "import pandas as pd\nfrom sklearn.preprocessing import PolynomialFeatures, StandardScaler\nfrom sklearn.linear_model import LinearRegression\n\n# Load datasets\ntrain_path = '/home/student/Desktop/PS_SOFTWARE/PS/backend/data/datasets/ml/bike/train.csv'\ntest_path = '/home/student/Desktop/PS_SOFTWARE/PS/backend/data/datasets/ml/bike/test.csv'\n\ndf_train = pd.read_csv(train_path)\ndf_test = pd.read_csv(test_path)\n\n# Feature engineering: extract hour from datetime\ndf_train['hour'] = pd.to_datetime(df_train['datetime']).dt.hour\ndf_test['hour'] = pd.to_datetime(df_test['datetime']).dt.hour\n\n# Select features and target\nfeatures = ['hour', 'temp', 'humidity', 'windspeed']\nX_train = df_train[features]\ny_train = df_train['count']\nX_test = df_test[features]\n\n# Scale features\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Polynomial transformation (degree 3)\npoly = PolynomialFeatures(degree=3, include_bias=False)\nX_train_poly = poly.fit_transform(X_train_scaled)\nX_test_poly = poly.transform(X_test_scaled)\n\n# Train Polynomial Regression model\nmodel = LinearRegression()\nmodel.fit(X_train_poly, y_train)\n\n# Predict on test set\ny_test_pred = model.predict(X_test_poly)\n\n# Save submission\nsubmission = pd.DataFrame({\n    'datetime': df_test['datetime'],\n    'count': y_test_pred\n})\nsubmission.to_csv('submission.csv', index=False)\nprint(\"Predictions saved to submission.csv\")",
        "passed": true
      },
      {
        "questionId": "LR_002",
        "partId": "Visualization",
        "code": "import pandas as pd\nfrom sklearn.preprocessing import PolynomialFeatures, StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import r2_score\n\n# Load training dataset\ntrain_path = '/home/student/Desktop/PS_SOFTWARE/PS/backend/data/datasets/ml/bike/train.csv'\ndf_train = pd.read_csv(train_path)\n\n# Feature engineering: extract hour\ndf_train['hour'] = pd.to_datetime(df_train['datetime']).dt.hour\n\n# Features and target\nfeatures = ['hour', 'temp', 'humidity', 'windspeed']\nX = df_train[features]\ny = df_train['count']\n\n# Scale features\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# Linear Regression\nlinear_model = LinearRegression()\nlinear_model.fit(X_scaled, y)\ny_pred_linear = linear_model.predict(X_scaled)\nr2_linear = r2_score(y, y_pred_linear)\n\n# Polynomial Regression (degree 3)\npoly = PolynomialFeatures(degree=3, include_bias=False)\nX_poly = poly.fit_transform(X_scaled)\n\npoly_model = LinearRegression()\npoly_model.fit(X_poly, y)\ny_pred_poly = poly_model.predict(X_poly)\nr2_poly = r2_score(y, y_pred_poly)\n\n# Print R\u00b2 scores\nprint(f\"Linear R-squared: {r2_linear:.4f}\")\nprint(f\"Polynomial R-squared: {r2_poly:.4f}\")\n\n# Concluding statement with keyword 'higher'\nif r2_poly > r2_linear:\n    print(\"Based on R\u00b2 scores, the Polynomial Regression model has a higher R\u00b2 and performed better than the Linear Regression model.\")\nelse:\n    print(\"Based on R\u00b2 scores, the Linear Regression model has a higher R\u00b2 and performed better than the Polynomial Regression model.\")",
        "passed": true
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "passed",
    "timestamp": "2025-09-12T16:25:55.006712",
    "answers": [
      {
        "questionId": "LR_002",
        "partId": "Feature Engineering",
        "code": "import pandas as pd\nfrom sklearn.preprocessing import PolynomialFeatures, StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import r2_score\n\n# Load training dataset\ntrain_path = '/home/student/Desktop/PS_SOFTWARE/PS/backend/data/datasets/ml/bike/train.csv'\ndf_train = pd.read_csv(train_path)\n\n# --- Part 1: Feature Engineering ---\n# Extract 'hour' from datetime\ndf_train['hour'] = pd.to_datetime(df_train['datetime']).dt.hour\n\n# Observation about relationship\nprint(\"The relationship between hour and bike rental count is likely non-linear (peaks during morning/evening).\")\n\n# Select features and target\nfeatures = ['hour', 'temp', 'humidity', 'windspeed']\nX = df_train[features]\ny = df_train['count']\n\n# Scale features\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# --- Part 2: Polynomial Feature Transformation ---\npoly = PolynomialFeatures(degree=2, include_bias=False)\nX_poly = poly.fit_transform(X_scaled)\n\n# --- Part 3: Train Polynomial Regression ---\nmodel = LinearRegression()\nmodel.fit(X_poly, y)\n\n# Predictions on training set\ny_pred_train = model.predict(X_poly)\nr2_train = r2_score(y, y_pred_train)\nprint(f\"Polynomial Regression R-squared (Train): {r2_train:.4f}\")\n\n",
        "passed": true
      },
      {
        "questionId": "LR_002",
        "partId": "Polynomial Regression",
        "code": "import pandas as pd\nfrom sklearn.preprocessing import PolynomialFeatures, StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import r2_score\n\n# Load training dataset\ntrain_path = '/home/student/Desktop/PS_SOFTWARE/PS/backend/data/datasets/ml/bike/train.csv'\ndf_train = pd.read_csv(train_path)\n\n# Feature engineering: extract hour from datetime\ndf_train['hour'] = pd.to_datetime(df_train['datetime']).dt.hour\n\n# Select features and target\nfeatures = ['hour', 'temp', 'humidity', 'windspeed']\nX = df_train[features]\ny = df_train['count']\n\n# Scale features\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# Polynomial transformation (degree 3)\npoly = PolynomialFeatures(degree=3, include_bias=False)\nX_poly = poly.fit_transform(X_scaled)\n\n# Train Polynomial Regression model\nmodel = LinearRegression()\nmodel.fit(X_poly, y)\n\n# Predict on training set\ny_pred_train = model.predict(X_poly)\n\n# R-squared score\nr2_train = r2_score(y, y_pred_train)\nprint(f\"Polynomial R-squared: {r2_train:.4f}\")",
        "passed": true
      },
      {
        "questionId": "LR_002",
        "partId": "Prediction & Analysis",
        "code": "import pandas as pd\nfrom sklearn.preprocessing import PolynomialFeatures, StandardScaler\nfrom sklearn.linear_model import LinearRegression\n\n# Load datasets\ntrain_path = '/home/student/Desktop/PS_SOFTWARE/PS/backend/data/datasets/ml/bike/train.csv'\ntest_path = '/home/student/Desktop/PS_SOFTWARE/PS/backend/data/datasets/ml/bike/test.csv'\n\ndf_train = pd.read_csv(train_path)\ndf_test = pd.read_csv(test_path)\n\n# Feature engineering: extract hour from datetime\ndf_train['hour'] = pd.to_datetime(df_train['datetime']).dt.hour\ndf_test['hour'] = pd.to_datetime(df_test['datetime']).dt.hour\n\n# Select features and target\nfeatures = ['hour', 'temp', 'humidity', 'windspeed']\nX_train = df_train[features]\ny_train = df_train['count']\nX_test = df_test[features]\n\n# Scale features\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Polynomial transformation (degree 3)\npoly = PolynomialFeatures(degree=3, include_bias=False)\nX_train_poly = poly.fit_transform(X_train_scaled)\nX_test_poly = poly.transform(X_test_scaled)\n\n# Train Polynomial Regression model\nmodel = LinearRegression()\nmodel.fit(X_train_poly, y_train)\n\n# Predict on test set\ny_test_pred = model.predict(X_test_poly)\n\n# Save submission\nsubmission = pd.DataFrame({\n    'datetime': df_test['datetime'],\n    'count': y_test_pred\n})\nsubmission.to_csv('submission.csv', index=False)\nprint(\"Predictions saved to submission.csv\")\n",
        "passed": true
      },
      {
        "questionId": "LR_002",
        "partId": "Visualization",
        "code": "import pandas as pd\nfrom sklearn.preprocessing import PolynomialFeatures, StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import r2_score\n\n# Load training dataset\ntrain_path = '/home/student/Desktop/PS_SOFTWARE/PS/backend/data/datasets/ml/bike/train.csv'\ndf_train = pd.read_csv(train_path)\n\n# Feature engineering: extract hour\ndf_train['hour'] = pd.to_datetime(df_train['datetime']).dt.hour\n\n# Features and target\nfeatures = ['hour', 'temp', 'humidity', 'windspeed']\nX = df_train[features]\ny = df_train['count']\n\n# Scale features\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# Linear Regression\nlinear_model = LinearRegression()\nlinear_model.fit(X_scaled, y)\ny_pred_linear = linear_model.predict(X_scaled)\nr2_linear = r2_score(y, y_pred_linear)\n\n# Polynomial Regression (degree 3)\npoly = PolynomialFeatures(degree=3, include_bias=False)\nX_poly = poly.fit_transform(X_scaled)\n\npoly_model = LinearRegression()\npoly_model.fit(X_poly, y)\ny_pred_poly = poly_model.predict(X_poly)\nr2_poly = r2_score(y, y_pred_poly)\n\n# Print R\u00b2 scores\nprint(f\"Linear R-squared: {r2_linear:.4f}\")\nprint(f\"Polynomial R-squared: {r2_poly:.4f}\")\n\n# Concluding statement with keyword 'higher'\nif r2_poly > r2_linear:\n    print(\"Based on R\u00b2 scores, the Polynomial Regression model has a higher R\u00b2 and performed better than the Linear Regression model.\")\nelse:\n    print(\"Based on R\u00b2 scores, the Linear Regression model has a higher R\u00b2 and performed better than the Polynomial Regression model.\")\n",
        "passed": true
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "failed",
    "timestamp": "2025-09-12T16:27:42.935357",
    "answers": [
      {
        "questionId": "LR_001",
        "partId": "Preprocessing",
        "code": "# Import necessary libraries\nimport pandas as pd\nimport numpy as np\n\n# Load the dataset\ntrain_path = '/home/student/Desktop/PS_SOFTWARE/PS/backend/data/datasets/ml/house-prices/train.csv'\ndf = pd.read_csv(train_path)\n\n# Display initial info\nprint(\"Initial Data Info:\")\nprint(df.info())\n\n# -----------------------------\n# 1. Handle Missing Values\n# -----------------------------\n# Fill numerical columns with median\nnum_cols = df.select_dtypes(include=[np.number]).columns.tolist()\ndf[num_cols] = df[num_cols].fillna(df[num_cols].median())\n\n# Fill categorical columns with mode\ncat_cols = df.select_dtypes(include=['object']).columns.tolist()\nfor col in cat_cols:\n    df[col] = df[col].fillna(df[col].mode()[0])\n\n# -----------------------------\n# 2. Handle Outliers\n# -----------------------------\n# Using IQR method for numeric columns\nfor col in num_cols:\n    Q1 = df[col].quantile(0.25)\n    Q3 = df[col].quantile(0.75)\n    IQR = Q3 - Q1\n    lower_bound = Q1 - 1.5 * IQR\n    upper_bound = Q3 + 1.5 * IQR\n    # Cap the outliers\n    df[col] = np.where(df[col] < lower_bound, lower_bound, df[col])\n    df[col] = np.where(df[col] > upper_bound, upper_bound, df[col])\n\n# Display cleaned dataframe info\nprint(\"\\nCleaned Data Info:\")\nprint(df.info())",
        "passed": true
      },
      {
        "questionId": "LR_001",
        "partId": "Model Training",
        "code": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import r2_score\n\n# Load dataset\ntrain_path = '/home/student/Desktop/PS_SOFTWARE/PS/backend/data/datasets/ml/house-prices/train.csv'\ndf = pd.read_csv(train_path)\n\n# Fill numeric missing values with median\nnum_cols = df.select_dtypes(include=['float64', 'int64']).columns.tolist()\ndf[num_cols] = df[num_cols].fillna(df[num_cols].median())\n\n# Use simpler feature set\nX = df[['OverallQual', 'GrLivArea', 'FullBath', 'BedroomAbvGr']]\ny = df['SalePrice']\n\n# Train-test split\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train Linear Regression\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# Predict on training set\ny_pred_train = model.predict(X_train)\nr2_train = r2_score(y_train, y_pred_train)\n\nprint(f\"R-squared Score: {r2_train:.4f}\") //0.7130",
        "passed": false
      },
      {
        "questionId": "LR_001",
        "partId": "Prediction",
        "code": "",
        "passed": false
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "passed",
    "timestamp": "2025-09-13T08:31:00.747054",
    "answers": [
      {
        "questionId": "LR_002",
        "partId": "Feature Engineering",
        "code": "import pandas as pd\nfrom sklearn.preprocessing import PolynomialFeatures, StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import r2_score\n\n# Load training dataset\ntrain_path = '/home/student/Desktop/PS_SOFTWARE/PS/backend/data/datasets/ml/bike/train.csv'\ndf_train = pd.read_csv(train_path)\n\n# --- Part 1: Feature Engineering ---\n# Extract 'hour' from datetime\ndf_train['hour'] = pd.to_datetime(df_train['datetime']).dt.hour\n\n# Observation about relationship\nprint(\"The relationship between hour and bike rental count is likely non-linear (peaks during morning/evening).\")\n\n# Select features and target\nfeatures = ['hour', 'temp', 'humidity', 'windspeed']\nX = df_train[features]\ny = df_train['count']\n\n# Scale features\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# --- Part 2: Polynomial Feature Transformation ---\npoly = PolynomialFeatures(degree=2, include_bias=False)\nX_poly = poly.fit_transform(X_scaled)\n\n# --- Part 3: Train Polynomial Regression ---\nmodel = LinearRegression()\nmodel.fit(X_poly, y)\n\n# Predictions on training set\ny_pred_train = model.predict(X_poly)\nr2_train = r2_score(y, y_pred_train)\nprint(f\"Polynomial Regression R-squared (Train): {r2_train:.4f}\")",
        "passed": true
      },
      {
        "questionId": "LR_002",
        "partId": "Polynomial Regression",
        "code": "import pandas as pd\nfrom sklearn.preprocessing import PolynomialFeatures, StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import r2_score\n\n# Load training dataset\ntrain_path = '/home/student/Desktop/PS_SOFTWARE/PS/backend/data/datasets/ml/bike/train.csv'\ndf_train = pd.read_csv(train_path)\n\n# Feature engineering: extract hour from datetime\ndf_train['hour'] = pd.to_datetime(df_train['datetime']).dt.hour\n\n# Select features and target\nfeatures = ['hour', 'temp', 'humidity', 'windspeed']\nX = df_train[features]\ny = df_train['count']\n\n# Scale features\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# Polynomial transformation (degree 3)\npoly = PolynomialFeatures(degree=3, include_bias=False)\nX_poly = poly.fit_transform(X_scaled)\n\n# Train Polynomial Regression model\nmodel = LinearRegression()\nmodel.fit(X_poly, y)\n\n# Predict on training set\ny_pred_train = model.predict(X_poly)\n\n# R-squared score\nr2_train = r2_score(y, y_pred_train)\nprint(f\"Polynomial R-squared: {r2_train:.4f}\")",
        "passed": true
      },
      {
        "questionId": "LR_002",
        "partId": "Prediction & Analysis",
        "code": "import pandas as pd\nfrom sklearn.preprocessing import PolynomialFeatures, StandardScaler\nfrom sklearn.linear_model import LinearRegression\n\n# Load datasets\ntrain_path = '/home/student/Desktop/PS_SOFTWARE/PS/backend/data/datasets/ml/bike/train.csv'\ntest_path = '/home/student/Desktop/PS_SOFTWARE/PS/backend/data/datasets/ml/bike/test.csv'\n\ndf_train = pd.read_csv(train_path)\ndf_test = pd.read_csv(test_path)\n\n# Feature engineering: extract hour from datetime\ndf_train['hour'] = pd.to_datetime(df_train['datetime']).dt.hour\ndf_test['hour'] = pd.to_datetime(df_test['datetime']).dt.hour\n\n# Select features and target\nfeatures = ['hour', 'temp', 'humidity', 'windspeed']\nX_train = df_train[features]\ny_train = df_train['count']\nX_test = df_test[features]\n\n# Scale features\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Polynomial transformation (degree 3)\npoly = PolynomialFeatures(degree=3, include_bias=False)\nX_train_poly = poly.fit_transform(X_train_scaled)\nX_test_poly = poly.transform(X_test_scaled)\n\n# Train Polynomial Regression model\nmodel = LinearRegression()\nmodel.fit(X_train_poly, y_train)\n\n# Predict on test set\ny_test_pred = model.predict(X_test_poly)\n\n# Save submission\nsubmission = pd.DataFrame({\n    'datetime': df_test['datetime'],\n    'count': y_test_pred\n})\nsubmission.to_csv('submission.csv', index=False)\nprint(\"Predictions saved to submission.csv\")",
        "passed": true
      },
      {
        "questionId": "LR_002",
        "partId": "Visualization",
        "code": "import pandas as pd\nfrom sklearn.preprocessing import PolynomialFeatures, StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import r2_score\n\n# Load training dataset\ntrain_path = '/home/student/Desktop/PS_SOFTWARE/PS/backend/data/datasets/ml/bike/train.csv'\ndf_train = pd.read_csv(train_path)\n\n# Feature engineering: extract hour\ndf_train['hour'] = pd.to_datetime(df_train['datetime']).dt.hour\n\n# Features and target\nfeatures = ['hour', 'temp', 'humidity', 'windspeed']\nX = df_train[features]\ny = df_train['count']\n\n# Scale features\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# Linear Regression\nlinear_model = LinearRegression()\nlinear_model.fit(X_scaled, y)\ny_pred_linear = linear_model.predict(X_scaled)\nr2_linear = r2_score(y, y_pred_linear)\n\n# Polynomial Regression (degree 3)\npoly = PolynomialFeatures(degree=3, include_bias=False)\nX_poly = poly.fit_transform(X_scaled)\n\npoly_model = LinearRegression()\npoly_model.fit(X_poly, y)\ny_pred_poly = poly_model.predict(X_poly)\nr2_poly = r2_score(y, y_pred_poly)\n\n# Print R\u00b2 scores\nprint(f\"Linear R-squared: {r2_linear:.4f}\")\nprint(f\"Polynomial R-squared: {r2_poly:.4f}\")\n\n# Concluding statement with keyword 'higher'\nif r2_poly > r2_linear:\n    print(\"Based on R\u00b2 scores, the Polynomial Regression model has a higher R\u00b2 and performed better than the Linear Regression model.\")\nelse:\n    print(\"Based on R\u00b2 scores, the Linear Regression model has a higher R\u00b2 and performed better than the Polynomial Regression model.\")",
        "passed": true
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "passed",
    "timestamp": "2025-09-13T08:54:03.981806",
    "answers": [
      {
        "questionId": "LR_002",
        "partId": "Feature Engineering",
        "code": "import pandas as pd\n\n# Paths\ntrain_path = '/home/student/Desktop/PS_SOFTWARE/PS/backend/data/datasets/ml/bike/train.csv'\ntest_path = '/home/student/Desktop/PS_SOFTWARE/PS/backend/data/datasets/ml/bike/test.csv'\n\n# Load train and test data\ntrain_df = pd.read_csv(train_path)\ntest_df = pd.read_csv(test_path)\n\n# Convert 'datetime' column to datetime type\ntrain_df['datetime'] = pd.to_datetime(train_df['datetime'])\ntest_df['datetime'] = pd.to_datetime(test_df['datetime'])\n\n# Extract 'hour' from datetime\ntrain_df['hour'] = train_df['datetime'].dt.hour\ntest_df['hour'] = test_df['datetime'].dt.hour\n\n# Quick check\nprint(train_df[['datetime', 'hour', 'count']].head())\n\n# Observation about relationship\nprint(\"Observation: The relationship between 'hour' and 'count' is likely non-linear, \"\n      \"as bike rentals usually peak during morning and evening rush hours and drop late at night.\")",
        "passed": true
      },
      {
        "questionId": "LR_002",
        "partId": "Polynomial Regression",
        "code": "# Part 2: Polynomial Regression\nimport pandas as pd\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score\n\n# Paths\ntrain_path = '/home/student/Desktop/PS_SOFTWARE/PS/backend/data/datasets/ml/bike/train.csv'\ntest_path = '/home/student/Desktop/PS_SOFTWARE/PS/backend/data/datasets/ml/bike/test.csv'\n\n# Load train and test data\ntrain_df = pd.read_csv(train_path)\ntest_df = pd.read_csv(test_path)\n\n# Convert 'datetime' to datetime type\ntrain_df['datetime'] = pd.to_datetime(train_df['datetime'])\ntest_df['datetime'] = pd.to_datetime(test_df['datetime'])\n\n# Feature Engineering: extract hour\ntrain_df['hour'] = train_df['datetime'].dt.hour\ntest_df['hour'] = test_df['datetime'].dt.hour\n\n# Select features and target\nfeatures = ['hour', 'temp', 'humidity']  # you can add more if available\nX = train_df[features]\ny = train_df['count']\n\n# Split train data for validation\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Polynomial features (degree 3)\npoly = PolynomialFeatures(degree=3, include_bias=False)\nX_train_poly = poly.fit_transform(X_train)\nX_val_poly = poly.transform(X_val)\n\n# Train Linear Regression on polynomial features\nmodel = LinearRegression()\nmodel.fit(X_train_poly, y_train)\n\n# Predict on validation set\ny_val_pred = model.predict(X_val_poly)\n\n# Evaluate R\u00b2 score\nr2 = r2_score(y_val, y_val_pred)\nprint(f\"Polynomial R-squared: {r2:.4f}\")",
        "passed": true
      },
      {
        "questionId": "LR_002",
        "partId": "Prediction & Analysis",
        "code": "# Part 3: Prediction & Analysis\nimport pandas as pd\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression\n\n# Paths\ntrain_path = '/home/student/Desktop/PS_SOFTWARE/PS/backend/data/datasets/ml/bike/train.csv'\ntest_path = '/home/student/Desktop/PS_SOFTWARE/PS/backend/data/datasets/ml/bike/test.csv'\n\n# Load train and test data\ntrain_df = pd.read_csv(train_path)\ntest_df = pd.read_csv(test_path)\n\n# Convert 'datetime' to datetime type\ntrain_df['datetime'] = pd.to_datetime(train_df['datetime'])\ntest_df['datetime'] = pd.to_datetime(test_df['datetime'])\n\n# Feature Engineering: extract hour\ntrain_df['hour'] = train_df['datetime'].dt.hour\ntest_df['hour'] = test_df['datetime'].dt.hour\n\n# Select features and target\nfeatures = ['hour', 'temp', 'humidity']  # can add more features if available\nX_train = train_df[features]\ny_train = train_df['count']\nX_test = test_df[features]\n\n# Polynomial features (degree 3)\npoly = PolynomialFeatures(degree=3, include_bias=False)\nX_train_poly = poly.fit_transform(X_train)\nX_test_poly = poly.transform(X_test)\n\n# Train model\nmodel = LinearRegression()\nmodel.fit(X_train_poly, y_train)\n\n# Predict on test set\ny_test_pred = model.predict(X_test_poly)\n\n# Prepare submission DataFrame\n# Keep ID column if exists in test set, else use row index\ntest_ids = test_df['datetime'] if 'datetime' in test_df.columns else pd.Series(range(len(test_df)))\nsubmission = pd.DataFrame({\n    'datetime': test_ids,\n    'count': y_test_pred\n})\n\n# Save to CSV\nsubmission.to_csv('submission.csv', index=False)\n\nprint(\"\u2705 Predictions saved to 'submission.csv'.\")",
        "passed": true
      },
      {
        "questionId": "LR_002",
        "partId": "Visualization",
        "code": "# Part 4: Visualization / Model Comparison\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score\n\n# Paths\ntrain_path = '/home/student/Desktop/PS_SOFTWARE/PS/backend/data/datasets/ml/bike/train.csv'\ntest_path = '/home/student/Desktop/PS_SOFTWARE/PS/backend/data/datasets/ml/bike/test.csv'\n\n# Load data\ntrain_df = pd.read_csv(train_path)\n\n# Convert 'datetime' to datetime type\ntrain_df['datetime'] = pd.to_datetime(train_df['datetime'])\n\n# Feature Engineering: extract hour\ntrain_df['hour'] = train_df['datetime'].dt.hour\n\n# Select features and target\nfeatures = ['hour', 'temp', 'humidity']\nX = train_df[features]\ny = train_df['count']\n\n# Split train data for validation\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# --- Linear Regression ---\nlin_model = LinearRegression()\nlin_model.fit(X_train, y_train)\ny_val_pred_lin = lin_model.predict(X_val)\nr2_linear = r2_score(y_val, y_val_pred_lin)\n\n# --- Polynomial Regression (degree 3) ---\npoly = PolynomialFeatures(degree=3, include_bias=False)\nX_train_poly = poly.fit_transform(X_train)\nX_val_poly = poly.transform(X_val)\n\npoly_model = LinearRegression()\npoly_model.fit(X_train_poly, y_train)\ny_val_pred_poly = poly_model.predict(X_val_poly)\nr2_poly = r2_score(y_val, y_val_pred_poly)\n\n# Concluding statement with 'higher' keyword\nif r2_poly > r2_linear:\n    print(f\"The Polynomial Regression model performed better because its R\u00b2 score ({r2_poly:.4f}) is higher than the Linear Regression R\u00b2 score ({r2_linear:.4f}).\")\nelse:\n    print(f\"The Linear Regression model performed better because its R\u00b2 score ({r2_linear:.4f}) is higher than the Polynomial Regression R\u00b2 score ({r2_poly:.4f}).\")",
        "passed": true
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "failed",
    "timestamp": "2025-09-13T10:09:14.318638",
    "answers": [
      {
        "questionId": "LR_004",
        "partId": "Data Exploration & Preprocessing",
        "code": "\n\n\n\n\n",
        "passed": false
      },
      {
        "questionId": "LR_004",
        "partId": "Hyperparameter Tuning",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_004",
        "partId": "Model Training & Evaluation",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_004",
        "partId": "Feature Selection Interpretation",
        "code": "",
        "passed": false
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "failed",
    "timestamp": "2025-09-13T10:10:01.199771",
    "answers": [
      {
        "questionId": "LR_001",
        "partId": "Preprocessing",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_001",
        "partId": "Model Training",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_001",
        "partId": "Prediction",
        "code": "",
        "passed": false
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "failed",
    "timestamp": "2025-09-13T10:11:00.016717",
    "answers": [
      {
        "questionId": "LR_006",
        "partId": "Data Preprocessing & Feature Engineering",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_006",
        "partId": "Hyperparameter Tuning",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_006",
        "partId": "Model Training & predictions",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_006",
        "partId": "Model evaluation & interpretation",
        "code": "",
        "passed": false
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "failed",
    "timestamp": "2025-09-13T10:11:07.277103",
    "answers": [
      {
        "questionId": "LR_002",
        "partId": "Feature Engineering",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_002",
        "partId": "Polynomial Regression",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_002",
        "partId": "Prediction & Analysis",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_002",
        "partId": "Visualization",
        "code": "",
        "passed": false
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "failed",
    "timestamp": "2025-09-13T10:35:31.624231",
    "answers": [
      {
        "questionId": "LR_007",
        "partId": "Data Preprocessing",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_007",
        "partId": "Hyperparameter Tuning",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_007",
        "partId": "Model Training & predictions",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_007",
        "partId": "Model evaluation & interpretation",
        "code": "",
        "passed": false
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "failed",
    "timestamp": "2025-09-13T13:25:47.380852",
    "answers": [
      {
        "questionId": "LR_006",
        "partId": "Data Preprocessing & Feature Engineering",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_006",
        "partId": "Hyperparameter Tuning",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_006",
        "partId": "Model Training & predictions",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_006",
        "partId": "Model evaluation & interpretation",
        "code": "",
        "passed": false
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "failed",
    "timestamp": "2025-09-13T13:26:41.683832",
    "answers": [
      {
        "questionId": "LR_008",
        "partId": "Data Preprocessing",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_008",
        "partId": "Hyperparameter Tuning",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_008",
        "partId": "Model Training & predictions",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_008",
        "partId": "Model evaluation & interpretation",
        "code": "",
        "passed": false
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "failed",
    "timestamp": "2025-09-13T13:29:24.027116",
    "answers": [
      {
        "questionId": "LR_001",
        "partId": "Preprocessing",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_001",
        "partId": "Model Training",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_001",
        "partId": "Prediction",
        "code": "",
        "passed": false
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "failed",
    "timestamp": "2025-09-13T13:33:39.607532",
    "answers": [
      {
        "questionId": "LR_006",
        "partId": "Data Preprocessing & Feature Engineering",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_006",
        "partId": "Hyperparameter Tuning",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_006",
        "partId": "Model Training & predictions",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_006",
        "partId": "Model evaluation & interpretation",
        "code": "",
        "passed": false
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "failed",
    "timestamp": "2025-09-13T13:33:39.610269",
    "answers": [
      {
        "questionId": "LR_006",
        "partId": "Data Preprocessing & Feature Engineering",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_006",
        "partId": "Hyperparameter Tuning",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_006",
        "partId": "Model Training & predictions",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_006",
        "partId": "Model evaluation & interpretation",
        "code": "",
        "passed": false
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "failed",
    "timestamp": "2025-09-13T13:57:37.021213",
    "answers": [
      {
        "questionId": "LR_003",
        "partId": "Data Exploration & Missing Values",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_003",
        "partId": "Feature Scaling & Preprocessing",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_003",
        "partId": "Model Training & Hyperparameter Tuning",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_003",
        "partId": "Model Evaluation,Interpretation of Coefficients",
        "code": "",
        "passed": false
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "failed",
    "timestamp": "2025-09-13T14:09:10.606471",
    "answers": [
      {
        "questionId": "LR_005",
        "partId": "Data Preprocessing",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_005",
        "partId": "Hyperparameter Tuning",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_005",
        "partId": "Model Performance",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_005",
        "partId": "Model evaluation & interpretation",
        "code": "",
        "passed": false
      }
    ]
  },
  {
    "subject": "ds",
    "level": "level2",
    "status": "failed",
    "timestamp": "2025-09-15T13:41:45.605960",
    "answers": [
      {
        "questionId": "reviews_task_v3",
        "partId": null,
        "code": "",
        "passed": false
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "failed",
    "timestamp": "2025-09-15T13:41:54.077568",
    "answers": [
      {
        "questionId": "LR_006",
        "partId": "Data Preprocessing & Feature Engineering",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_006",
        "partId": "Hyperparameter Tuning",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_006",
        "partId": "Model Training & predictions",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_006",
        "partId": "Model evaluation & interpretation",
        "code": "",
        "passed": false
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "failed",
    "timestamp": "2025-09-15T13:43:06.782073",
    "answers": [
      {
        "questionId": "LR_003",
        "partId": "Data Exploration & Missing Values",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_003",
        "partId": "Feature Scaling & Preprocessing",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_003",
        "partId": "Model Training & Hyperparameter Tuning",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_003",
        "partId": "Model Evaluation,Interpretation of Coefficients",
        "code": "",
        "passed": false
      }
    ]
  },
  {
    "subject": "ds",
    "level": "level1",
    "status": "failed",
    "timestamp": "2025-09-15T13:43:57.256386",
    "answers": [
      {
        "questionId": "q6",
        "partId": null,
        "code": "",
        "passed": false
      },
      {
        "questionId": "q1",
        "partId": null,
        "code": "",
        "passed": false
      },
      {
        "questionId": "q4",
        "partId": null,
        "code": "",
        "passed": false
      },
      {
        "questionId": "q2",
        "partId": null,
        "code": "",
        "passed": false
      },
      {
        "questionId": "q9",
        "partId": null,
        "code": "",
        "passed": false
      }
    ]
  },
  {
    "subject": "ds",
    "level": "level1",
    "status": "failed",
    "timestamp": "2025-09-15T13:44:09.338691",
    "answers": [
      {
        "questionId": "q6",
        "partId": null,
        "code": "",
        "passed": false
      },
      {
        "questionId": "q1",
        "partId": null,
        "code": "",
        "passed": false
      },
      {
        "questionId": "q4",
        "partId": null,
        "code": "",
        "passed": false
      },
      {
        "questionId": "q2",
        "partId": null,
        "code": "",
        "passed": false
      },
      {
        "questionId": "q9",
        "partId": null,
        "code": "",
        "passed": false
      }
    ]
  },
  {
    "subject": "ds",
    "level": "level1",
    "status": "failed",
    "timestamp": "2025-09-15T13:44:20.954278",
    "answers": [
      {
        "questionId": "q6",
        "partId": null,
        "code": "",
        "passed": false
      },
      {
        "questionId": "q1",
        "partId": null,
        "code": "",
        "passed": false
      },
      {
        "questionId": "q4",
        "partId": null,
        "code": "",
        "passed": false
      },
      {
        "questionId": "q2",
        "partId": null,
        "code": "",
        "passed": false
      },
      {
        "questionId": "q9",
        "partId": null,
        "code": "",
        "passed": false
      }
    ]
  },
  {
    "subject": "ds",
    "level": "level1",
    "status": "failed",
    "timestamp": "2025-09-15T13:46:02.608189",
    "answers": [
      {
        "questionId": "q2",
        "partId": null,
        "code": "",
        "passed": false
      },
      {
        "questionId": "q4",
        "partId": null,
        "code": "",
        "passed": false
      },
      {
        "questionId": "q7",
        "partId": null,
        "code": "",
        "passed": false
      },
      {
        "questionId": "q9",
        "partId": null,
        "code": "",
        "passed": false
      },
      {
        "questionId": "q5",
        "partId": null,
        "code": "",
        "passed": false
      }
    ]
  },
  {
    "subject": "ds",
    "level": "level1",
    "status": "failed",
    "timestamp": "2025-09-15T13:46:39.775090",
    "answers": [
      {
        "questionId": "q8",
        "partId": null,
        "code": "",
        "passed": false
      },
      {
        "questionId": "q3",
        "partId": null,
        "code": "",
        "passed": false
      },
      {
        "questionId": "q4",
        "partId": null,
        "code": "",
        "passed": false
      },
      {
        "questionId": "q1",
        "partId": null,
        "code": "",
        "passed": false
      },
      {
        "questionId": "q9",
        "partId": null,
        "code": "",
        "passed": false
      }
    ]
  },
  {
    "subject": "ds",
    "level": "level2",
    "status": "failed",
    "timestamp": "2025-09-15T13:47:02.215440",
    "answers": [
      {
        "questionId": "reviews_task_v3",
        "partId": null,
        "code": "",
        "passed": false
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "failed",
    "timestamp": "2025-09-15T13:54:58.360517",
    "answers": [
      {
        "questionId": "LR_004",
        "partId": "Data Exploration & Preprocessing",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_004",
        "partId": "Hyperparameter Tuning",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_004",
        "partId": "Model Training & Evaluation",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_004",
        "partId": "Feature Selection Interpretation",
        "code": "",
        "passed": false
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "failed",
    "timestamp": "2025-09-15T14:20:31.316264",
    "answers": [
      {
        "questionId": "LR_003",
        "partId": "Data Exploration & Missing Values",
        "code": "print(10)",
        "passed": false
      },
      {
        "questionId": "LR_003",
        "partId": "Feature Scaling & Preprocessing",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_003",
        "partId": "Model Training & Hyperparameter Tuning",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_003",
        "partId": "Model Evaluation,Interpretation of Coefficients",
        "code": "",
        "passed": false
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "failed",
    "timestamp": "2025-09-15T14:30:45.279797",
    "answers": [
      {
        "questionId": "LR_008",
        "partId": "Data Preprocessing",
        "code": "\n\n\n\n\n\n\n",
        "passed": false
      },
      {
        "questionId": "LR_008",
        "partId": "Hyperparameter Tuning",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_008",
        "partId": "Model Training & predictions",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_008",
        "partId": "Model evaluation & interpretation",
        "code": "",
        "passed": false
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "failed",
    "timestamp": "2025-09-15T14:30:46.891595",
    "answers": [
      {
        "questionId": "LR_008",
        "partId": "Data Preprocessing",
        "code": "\n\n\n\n\n\n\n",
        "passed": false
      },
      {
        "questionId": "LR_008",
        "partId": "Hyperparameter Tuning",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_008",
        "partId": "Model Training & predictions",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_008",
        "partId": "Model evaluation & interpretation",
        "code": "",
        "passed": false
      }
    ]
  },
  {
    "subject": "ml",
    "level": "level1",
    "status": "failed",
    "timestamp": "2025-09-15T14:32:40.981757",
    "answers": [
      {
        "questionId": "LR_004",
        "partId": "Data Exploration & Preprocessing",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_004",
        "partId": "Hyperparameter Tuning",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_004",
        "partId": "Model Training & Evaluation",
        "code": "",
        "passed": false
      },
      {
        "questionId": "LR_004",
        "partId": "Feature Selection Interpretation",
        "code": "",
        "passed": false
      }
    ]
  },
  {
    "subject": "ds",
    "level": "level1",
    "status": "failed",
    "timestamp": "2025-09-15T14:52:34.351653",
    "answers": [
      {
        "questionId": "q8",
        "partId": null,
        "code": "",
        "passed": false
      },
      {
        "questionId": "q7",
        "partId": null,
        "code": "",
        "passed": false
      },
      {
        "questionId": "q2",
        "partId": null,
        "code": "",
        "passed": false
      },
      {
        "questionId": "q1",
        "partId": null,
        "code": "",
        "passed": false
      },
      {
        "questionId": "q5",
        "partId": null,
        "code": "",
        "passed": false
      }
    ]
  },
  {
    "subject": "ds",
    "level": "level1",
    "status": "failed",
    "timestamp": "2025-09-15T14:56:29.017714",
    "answers": [
      {
        "questionId": "q9",
        "partId": null,
        "code": "n = int(input())\nprint(\"[\")\nfor i in range(1,n+1):\n    print(i,end=0)\nprint(\"]\")",
        "passed": false
      },
      {
        "questionId": "q1",
        "partId": null,
        "code": "",
        "passed": false
      },
      {
        "questionId": "q10",
        "partId": null,
        "code": "",
        "passed": false
      },
      {
        "questionId": "q2",
        "partId": null,
        "code": "",
        "passed": false
      },
      {
        "questionId": "q4",
        "partId": null,
        "code": "",
        "passed": false
      }
    ]
  },
  {
    "subject": "ds",
    "level": "level1",
    "status": "failed",
    "timestamp": "2025-09-15T14:56:30.411559",
    "answers": [
      {
        "questionId": "q9",
        "partId": null,
        "code": "n = int(input())\nprint(\"[\")\nfor i in range(1,n+1):\n    print(i,end=0)\nprint(\"]\")",
        "passed": false
      },
      {
        "questionId": "q1",
        "partId": null,
        "code": "",
        "passed": false
      },
      {
        "questionId": "q10",
        "partId": null,
        "code": "",
        "passed": false
      },
      {
        "questionId": "q2",
        "partId": null,
        "code": "",
        "passed": false
      },
      {
        "questionId": "q4",
        "partId": null,
        "code": "",
        "passed": false
      }
    ]
  },
  {
    "subject": "ds",
    "level": "level1",
    "status": "failed",
    "timestamp": "2025-09-15T15:33:50.292415",
    "answers": [
      {
        "questionId": "q4",
        "partId": null,
        "code": "# Read input\nnumbers = list(map(int, input().split()))\n\n# Count elements\ncount = len(numbers)\n\n# Print result\nprint(count)\n",
        "passed": false
      },
      {
        "questionId": "q2",
        "partId": null,
        "code": "",
        "passed": false
      },
      {
        "questionId": "q8",
        "partId": null,
        "code": "",
        "passed": false
      },
      {
        "questionId": "q6",
        "partId": null,
        "code": "",
        "passed": false
      },
      {
        "questionId": "q1",
        "partId": null,
        "code": "",
        "passed": false
      }
    ]
  },
  {
    "subject": "ds",
    "level": "level1",
    "status": "passed",
    "timestamp": "2025-09-15T15:50:01.484234",
    "answers": [
      {
        "questionId": "q9",
        "partId": null,
        "code": "import numpy as np\n\n# Read input\nn = int(input())\n\n# Create number sequence from 1 to n\narr = np.arange(1, n + 1)\n\n# Print result\nprint(arr)\n",
        "passed": true
      },
      {
        "questionId": "q1",
        "partId": null,
        "code": "import numpy as np\n\n# Create NumPy array\narr = np.array([1, 2, 3])\n\n# Print array\nprint(arr)\n",
        "passed": true
      },
      {
        "questionId": "q7",
        "partId": null,
        "code": "# Read input\nnumbers = list(map(int, input().split()))\n\n# Print first element\nprint(numbers[0])\n",
        "passed": true
      },
      {
        "questionId": "q6",
        "partId": null,
        "code": "import numpy as np\n\n# Read input\nnumbers = list(map(int, input().split()))\n\n# Create NumPy array\narr = np.array(numbers)\n\n# Double all numbers\narr = arr * 2\n\n# Print result\nprint(arr)\n",
        "passed": true
      },
      {
        "questionId": "q4",
        "partId": null,
        "code": "# Read input\nnumbers = list(map(int, input().split()))\n\n# Print number of elements\nprint(len(numbers))\n",
        "passed": true
      }
    ]
  }
]