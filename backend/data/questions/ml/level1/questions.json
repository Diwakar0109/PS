[
  {
    "id": "LR_001",
    "title": "Predict the house price.",
    "description": "A real estate company wants to predict house prices based\non historical data. You are given a dataset containing \nfeatures like number of rooms, area (in square feet), \nnumber of bathrooms, location rating, and\nage of the house.\n\nDataset Paths: https://www.kaggle.com/c/house-\nprices-advanced-regression-\ntechniques/data\n\nParts: Preprocessing,Model Training,\nPrediction\n\nExpected Outputs: Predict the missing values,\nTrain a Linear Regression model,\nPredict the price\n\nValidation Method: Text similarity,Code execution,CSV \nsimilarity,Regression method,Numerical predictions\n\nSolution File: https://drive.google.com/drive/folders/16SBn96\nJVI5-ruYHiEsLlQGfO2sF-63lJ?usp=drive_link",
    "datasets": {},
    "parts": [
      {
        "part_id": "Preprocessing",
        "type": "",
        "description": "Part 1:Preprocessing\n\nPredict the missing values or outliers in this dataset. Show code and results.",
        "similarity_threshold": 0.8
      },
      {
        "part_id": "Model Training",
        "type": "",
        "description": "Part 2:Model Training\n\nTrain a Linear Regression model and evaluate its performance\nusing RMSE and R\u00b2 score. Show the results.",
        "similarity_threshold": 0.8
      },
      {
        "part_id": "Prediction",
        "type": "",
        "description": "Part 3:Prediction\n\nPredict the price of a house with the following features:",
        "similarity_threshold": 0.8
      },
      {
        "part_id": "Project ID",
        "type": "",
        "description": "Title\n\nDescription",
        "expected_text": "Expected Outputs"
      }
    ]
  },
  {
    "id": "LR_002",
    "title": "Predicts sales based on \nadvertising budgets.",
    "description": "A marketing company wants to understand how advertising \nspending influences product sales.They have collected data on\ntheir advertising budget (in thousands of dollars) spent on TV,\nradio, and newspaper ads, along with the sales numbers \n(in thousands of units).Your task is to build a Linear \nRegression model that predicts sales based on advertising \nbudgets.\n\nDataset Paths: https://raw.githubusercontent.com/\nselva86/datasets/master/\nAdvertising.csv\n\nParts: Missing values check,Summary \nstatistics,Model coefficients &\nintercept,Evaluation metrics \n(MSE &amp; R\u00b2),Prediction output\n\nExpected Outputs: All zeros (no missing values),\nReasonable mean, std values,\nCoefficients close to example values,\nMSE ~2.1, R\u00b2 ~0.9,Predicted sales ~17.8\n\nValidation Method: Text similarity,Code execution,CSV \nsimilarity\n\nSolution File: https://drive.google.com/drive/folders/16SBn96\nJVI5-ruYHiEsLlQGfO2sF-63lJ?usp=drive_link",
    "datasets": {},
    "parts": [
      {
        "part_id": "Missing values \ncheck",
        "type": "",
        "description": "Part 1:\"Missing values \ncheck\"\n\nCheck for any missing values in the dataset. Provide summary \nstatistics (mean, median, std) of the features and target variable.",
        "similarity_threshold": 0.8
      },
      {
        "part_id": "Summary",
        "type": "",
        "description": "Part 2:Summary\n\nBuild a multiple linear regression model using all three features \n(TV, Radio, Newspaper) to predict Sales.",
        "similarity_threshold": 0.8
      },
      {
        "part_id": "Model coefficients \n& intercept",
        "type": "",
        "description": "Part 3:\"Model coefficients \n& intercept\"\n\nReport the model coefficients and intercept.",
        "similarity_threshold": 0.8
      },
      {
        "part_id": "Evaluation metrics \n(MSE &amp; R\u00b2)",
        "type": "",
        "description": "Part 4: \"Evaluation metrics \n(MSE &amp; R\u00b2)\"\n\nEvaluate the model using Mean Squared Error (MSE) and R\u00b2 \nscore on a train-test split (80%-20%).",
        "similarity_threshold": 0.8
      },
      {
        "part_id": "Prediction output",
        "type": "",
        "description": "Part 5: Prediction output\n\nUse your model to predict sales if the advertising budgets are:\n\n\u25cb TV = 150\n\u25cb Radio = 30\n\u25cb Newspaper = 20",
        "similarity_threshold": 0.8
      },
      {
        "part_id": "Project ID",
        "type": "",
        "description": "Title\n\nDescription",
        "expected_text": "Expected Outputs"
      }
    ]
  },
  {
    "id": "LR_003",
    "title": "predict hourly bike rental \ndemand based on weather \nand temporal features",
    "description": "A city bike rental company wants to understand and predict the \nnumber of bikes rented in a given hour based on various factors \nlike temperature, humidity, and time of day. The relationship \nbetween these factors and bike demand is likely non-linear.\nYour task is to build a Polynomial Regression model to predict \nhourly bike rental demand based on weather and temporal \nfeatures using the dataset provided.\n\nDataset Paths: https://www.kaggle.com/competitions\n/bike-sharing-demand/data\n\nParts: Feature Engineering,Polynomial \nRegression,Prediction & Analysis,\nVisualization\n\nExpected Outputs: Extracted hour, cleaned data, plotted relationships\nImplemented correctly, used appropriate degree, \ncompare models,Performed predictions, \ninterpreted results correctly,Plotted nonlinear \nrelationships (optional bonus)\n\nValidation Method: Text similarity,Code execution,CSV \nsimilarity,Regression evaluation\n\nSolution File: https://drive.google.com/drive/folders/16SBn96\nJVI5-ruYHiEsLlQGfO2sF-63lJ?usp=drive_link",
    "datasets": {},
    "parts": [
      {
        "part_id": "Feature \nEngineering",
        "type": "",
        "description": "Part 1:\"Feature \nEngineering\"\n\nExtract the hour from the datetime column and plot the relationship\nbetween hour and count. Does the relationship look linear or \nnon-linear?",
        "similarity_threshold": 0.8
      },
      {
        "part_id": "Polynomial \nRegression",
        "type": "",
        "description": "Part 2:\"Polynomial \nRegression\"\n\nUse Polynomial Regression (degree=2 or 3) to model the \nrelationship between hour and bike rental count. \nCompare it with a simple Linear Regression model using R\u00b2 score.",
        "similarity_threshold": 0.8
      },
      {
        "part_id": "Prediction & \nAnalysis",
        "type": "",
        "description": "Part 3:\"Prediction & \nAnalysis\"\n\nUsing your trained polynomial model, predict the number of bike \nrentals",
        "similarity_threshold": 0.8
      },
      {
        "part_id": "Visualization",
        "type": "",
        "description": "Part 4: Visualization\n\nR\u00b2 Score - Linear Regression: 0.320\nR\u00b2 Score - Polynomial Regression (deg=3): 0.470",
        "similarity_threshold": 0.8
      },
      {
        "part_id": "Project ID",
        "type": "",
        "description": "Title\n\nDescription",
        "expected_text": "Expected Outputs"
      }
    ]
  },
  {
    "id": "LR_004",
    "title": "Build a ridge regression \nmodel to predict house \nprices",
    "description": "You are working as a data scientist for a real estate company. \nYour goal is to build a regression model to predict house prices \nusing various features such as lot area, number of bedrooms, \nyear built, and overall quality. However, due to multicollinearity \namong some features, you want to use Ridge Regression to\nimprove model stability and performance by applying L2 \nregularization.\n\nDataset Paths: https://www.kaggle.com/c/house-\nprices-advanced-regression-\ntechniques/data\n\nParts: Data Exploration & Missing Values,\nFeature Scaling & Preprocessing,\nModel Training & Hyperparameter \nTuning,Model Evaluation,Interpretation\nof Coefficients\n\nExpected Outputs: Missing values before and after imputation printed\nTotalBsmtSF missing values handled correctly,\nFeatures scaled before Ridge and Linear \nRegression training,Found best alpha parameter\n(e.g., alpha=10) and trained Ridge model \naccordingly,Ridge should have similar or\nbetter RMSE and R\u00b2 than Linear\nRegression,Ridge coefficients should be\nsmaller in magnitude; student\nexplains regularization impact\n\nValidation Method: Text similarity,Code execution,CSV \nsimilarity,Regression evaluation\n\nSolution File: https://drive.google.com/drive/folders/16SBn96\nJVI5-ruYHiEsLlQGfO2sF-63lJ?usp=drive_link",
    "datasets": {},
    "parts": [
      {
        "part_id": "Data Exploration & \nMissing Values",
        "type": "",
        "description": "Part 1:Data Exploration & \nMissing Values\n\nMissing values before and after imputation printed:TotalBsmtSF \nmissing values handled correctly",
        "similarity_threshold": 0.8
      },
      {
        "part_id": "Feature Scaling & \nPreprocessing",
        "type": "",
        "description": "Part 2:\"Feature Scaling & \nPreprocessing\"\"\n\nFeatures scaled before Ridge and Linear Regression training",
        "similarity_threshold": 0.8
      },
      {
        "part_id": "Model Training & \nHyperparameter Tuning",
        "type": "",
        "description": "Part 3:\"Model Training & \nHyperparameter Tuning\"\n\nFound best alpha parameter (e.g., alpha=10) and trained\nRidge model accordingly",
        "similarity_threshold": 0.8
      },
      {
        "part_id": "Model Evaluation,\nInterpretation of \nCoefficients",
        "type": "",
        "description": "Part 4: \"Model Evaluation,\nInterpretation of \nCoefficients\"\n\nRidge should have similar or better RMSE and R\u00b2 than Linear\nRegression,Ridge coefficients should be smaller in magnitude \nstudent explains regularization impact",
        "similarity_threshold": 0.8
      },
      {
        "part_id": "Project ID",
        "type": "",
        "description": "Title\n\nDescription",
        "expected_text": "Expected Outputs"
      }
    ]
  },
  {
    "id": "LR_005",
    "title": "Build a predictive model to \nestimate the progression of \ndiabetes",
    "description": "You are tasked with building a predictive model to estimate the \nprogression of diabetes one year after baseline, based on various \nmedical features. Since the dataset contains multiple correlated \nfeatures, use Lasso Regression to perform both regression and \nfeature selection, by enforcing sparsity in the model\ncoefficients.\n\nDataset Paths: https://www.kaggle.com/datasets/\nuciml/pima-indians-diabetes-database\n\nParts: Data Exploration & Preprocessing,\nHyperparameter Tuning,Model Training\n& Evaluation,Feature Selection\nInterpretation\n\nExpected Outputs: Identified no or handled missing data;summarized \nfeatures,Found and reported best alpha (e.g.,0.01),\nLasso RMSE and R\u00b2 close to Linear Regression,\nSome coefficients zeroed; explained regularization\neffect\n\nValidation Method: Text similarity,Code execution,CSV \nsimilarity,Regression evaluation\n\nSolution File: https://drive.google.com/drive/folders/16SBn96\nJVI5-ruYHiEsLlQGfO2sF-63lJ?usp=drive_link",
    "datasets": {},
    "parts": [
      {
        "part_id": "Data Exploration & \nPreprocessing",
        "type": "",
        "description": "Part 1:\"Data Exploration & \nPreprocessing\"\"Feature \nEngineering\"\n\nChecked for missing values and handled appropriately",
        "similarity_threshold": 0.8
      },
      {
        "part_id": "Hyperparameter Tuning",
        "type": "",
        "description": "Part 2:Hyperparameter \nTuning\n\nUsed GridSearchCV to find best alpha",
        "similarity_threshold": 0.8
      },
      {
        "part_id": "Model Training\n& Evaluation",
        "type": "",
        "description": "Part 3:\"Model Training\n& Evaluation\"\n\nTrained Linear &amp; Lasso models; computed RMSE and R\u00b2",
        "similarity_threshold": 0.8
      },
      {
        "part_id": "Feature Selection\nInterpretation",
        "type": "",
        "description": "Part 4: \"Feature Selection\nInterpretation\"\n\nIdentified zero coefficients in Lasso; explained feature elimination",
        "similarity_threshold": 0.8
      },
      {
        "part_id": "Project ID",
        "type": "",
        "description": "Title\n\nDescription",
        "expected_text": "Expected Outputs"
      }
    ]
  },
  {
    "id": "LR_006",
    "title": "build a classification model that \ncan accurately identify \ndiabetic patients.",
    "description": "You are provided with a dataset containing medical diagnostic \nmeasurements for women of at least 21 years old, some of whom \nhave diabetes. Your task is to build a logistic regression model to \npredict whether a patient has diabetes based on these features. \nThe goal is to build a classification model that can accurately \nidentify diabetic patients.\n\nDataset Paths: https://www.kaggle.com/uciml/pima-\nindians-diabetes-database\n\nParts: Data Preprocessing & EDA,Hyperparameter\nTuning,Model Performance,Interpretation of\nResults\n\nExpected Outputs: Correct imputation of zeros, use of StandardScaler,\nFound best C around 0.1 to 10 with reasoning,\nMetrics similar to expected ,(accuracy ~0.79, ROC \nAUC &gt;0.8),Meaningful insights on coefficient signs \nand class metrics\n\nValidation Method: Text similarity,Code execution,CSV \nsimilarity,Regression evaluation\n\nSolution File: https://drive.google.com/drive/folders/16SBn96\nJVI5-ruYHiEsLlQGfO2sF-63lJ?usp=drive_link",
    "datasets": {},
    "parts": [
      {
        "part_id": "Data Preprocessing & \nEDA",
        "type": "",
        "description": "Part 1:\"Data Preprocessing & \nEDA\"\n\nHandling missing/zero values and\nscaling appropriately",
        "similarity_threshold": 0.8
      },
      {
        "part_id": "Hyperparameter Tuning",
        "type": "",
        "description": "Part 2:Hyperparameter \nTuning\n\nUsage of GridSearchCV to find\noptimal C parameter",
        "similarity_threshold": 0.8
      },
      {
        "part_id": "Model Performance",
        "type": "",
        "description": "Part 3:Model Performance\n\nCalculation and interpretation of\naccuracy, precision, recall, F1,\nand ROC-AUC",
        "similarity_threshold": 0.8
      },
      {
        "part_id": "Interpretation of\nResults",
        "type": "",
        "description": "Part 4: \"Interpretation of\nResults\"\n\nInterpretation of coefficients and\nclassification report",
        "similarity_threshold": 0.8
      },
      {
        "part_id": "Project ID",
        "type": "",
        "description": "Title\n\nDescription",
        "expected_text": "Expected Outputs"
      }
    ]
  },
  {
    "id": "LR_007",
    "title": "Predict house price using\ntree based prediction",
    "description": "You are provided with a dataset containing various features of \nhouses (size, number of rooms, location, etc.) and their \ncorresponding sale prices. Your task is to build regression models \nusing tree-based methods \u2014 specifically Decision Tree \nRegression and Random Forest Regression \u2014 to predict house \nprices. Analyze and compare their performances, and discuss \nwhich model better suits the problem.\n\nDataset Paths: https://www.kaggle.com/c/house-\nprices-advanced-regression-\ntechniques/data\n\nParts: Data Preprocessing ,Hyperparameter\nTuning,Model Performance,Model \nevaluation & interpretation\n\nExpected Outputs: Imputed missing values, used OneHotEncoder for\ncategoricals,Best params within reasonable ranges \nas above,Both models trained predictions made \nwithout errors,Random Forest performs better \nRMSE lower, R\u00b2 higher\n\nValidation Method: Text similarity,Code execution,CSV \nsimilarity,Regression evaluation\n\nSolution File: https://drive.google.com/drive/folders/16SBn96\nJVI5-ruYHiEsLlQGfO2sF-63lJ?usp=drive_link",
    "datasets": {},
    "parts": [
      {
        "part_id": "Data Preprocessing",
        "type": "",
        "description": "Part 1:\"Data Preprocessing\n\nHandling missing data, encoding categoricals correctly",
        "similarity_threshold": 0.8
      },
      {
        "part_id": "Hyperparameter Tuning",
        "type": "",
        "description": "Part 2:Hyperparameter \nTuning\n\nPerformed GridSearchCV and\nfound reasonable parameters",
        "similarity_threshold": 0.8
      },
      {
        "part_id": "Model Performance",
        "type": "",
        "description": "Part 3:Model Performance\n\nTrained Decision Tree and\nRandom Forest models and\npredicted test values",
        "similarity_threshold": 0.8
      },
      {
        "part_id": "Model evaluation & \ninterpretation",
        "type": "",
        "description": "Part 4: Model evaluation & \ninterpretation\n\nReported RMSE and R\u00b2,\ninterpreted which model\nperforms better",
        "similarity_threshold": 0.8
      },
      {
        "part_id": "Project ID",
        "type": "",
        "description": "Title\n\nDescription",
        "expected_text": "Expected Outputs"
      }
    ]
  },
  {
    "id": "LR_008",
    "title": "Your task is to build a \nRandom Forest Regression \nmodel to predict the number \nof bike rentals (count)",
    "description": "You are provided with a dataset that records hourly bike rental \ncounts in the Capital Bikeshare system along with weather and \nseasonal information. Your task is to build a Random Forest \nRegression model to predict the number of bike rentals (count) \nbased on various features such as temperature, humidity, wind \nspeed, season, and weather conditions. Evaluate the models \nperformance and interpret the important features affecting bike \ndemand.\n\nDataset Paths: https://www.kaggle.com/c/bike-sharing-\ndemand/data\n\nParts: Data Preprocessing & Feature Engineering,\nHyperparameter Tuning, Model Training \n& Predictions,Model Evaluation &\nInterpretation\n\nExpected Outputs: Correct feature extraction (hour, month, year), encoding\napplied properly,Found reasonable best parameters \nsimilar to expected output,Model successfully predicts\ntest set values,Metrics around RMSE ~70, R\u00b2\n~0.85; meaningful feature importance explanation\n\nValidation Method: Text similarity,Code execution,CSV \nsimilarity,Regression evaluation\n\nSolution File: https://drive.google.com/drive/folders/16SBn96\nJVI5-ruYHiEsLlQGfO2sF-63lJ?usp=drive_link",
    "datasets": {},
    "parts": [
      {
        "part_id": "Data Preprocessing &\nFeature Engineering",
        "type": "",
        "description": "Part 1:Data Preprocessing \n& Feature Engineering\n\nHandled datetime features,categorical encoding, missing data",
        "similarity_threshold": 0.8
      },
      {
        "part_id": "Hyperparameter Tuning",
        "type": "",
        "description": "Part 2:Hyperparameter \nTuning\n\nUsed GridSearchCV to tune parameters and selected best model",
        "similarity_threshold": 0.8
      },
      {
        "part_id": "Model Training & \npredictions",
        "type": "",
        "description": "Part 3:Model Training & \npredictions\n\nModel trained and predicted on test set without errors",
        "similarity_threshold": 0.8
      },
      {
        "part_id": "Model evaluation & \ninterpretation",
        "type": "",
        "description": "Part 4: Model evaluation & \ninterpretation\n\nReported RMSE and R\u00b2; explained feature importance and \nmodel insights",
        "similarity_threshold": 0.8
      },
      {
        "part_id": "Project ID",
        "type": "",
        "description": "Title\n\nDescription",
        "expected_text": "Expected Outputs"
      }
    ]
  },
  {
    "id": "LR_009",
    "title": "Your task is to build a \nGradient Boosting \nRegression model to predict \nhouse sale prices.",
    "description": "You are given a dataset with various features describing houses, \nsuch as size, location, year built, and more. Your task is to build a \nGradient Boosting Regression model to predict house sale prices.\nYou need to preprocess the data, tune the hyperparameters of the\nGradient Boosting Regressor, evaluate the model, and identify \nthe most important features affecting the price.\n\nDataset Paths: https://www.kaggle.com/c/house-prices-\nadvanced-regression-techniques/data\n\nParts: Data Preprocessing,\nHyperparameter Tuning, Model Training \n& Predictions,Model Evaluation &\nInterpretation\n\nExpected Outputs: Missing values imputed categorical features one-hot \nencoded, Found sensible best parameters (similar to\nabove),Predictions completed successfully, \nRMSE ~28000, R\u00b2 ~0.85+ meaningful feature\nimportance analysis\n\nValidation Method: Text similarity,Code execution,CSV \nsimilarity,Regression evaluation\n\nSolution File: https://drive.google.com/drive/folders/16SBn96\nJVI5-ruYHiEsLlQGfO2sF-63lJ?usp=drive_link",
    "datasets": {},
    "parts": [
      {
        "part_id": "Data Preprocessing",
        "type": "",
        "description": "Part 1:Data Preprocessing\n\nHandled datetime features,categorical encoding, missing data",
        "similarity_threshold": 0.8
      },
      {
        "part_id": "Hyperparameter Tuning",
        "type": "",
        "description": "Part 2:Hyperparameter \nTuning\n\nUsed GridSearchCV to tune parameters and selected best model",
        "similarity_threshold": 0.8
      },
      {
        "part_id": "Model Training & \npredictions",
        "type": "",
        "description": "Part 3:Model Training & \npredictions\n\nModel trained and predicted on test set without errors",
        "similarity_threshold": 0.8
      },
      {
        "part_id": "Model evaluation & \ninterpretation",
        "type": "",
        "description": "Part 4: Model evaluation & \ninterpretation\n\nReported RMSE and R\u00b2; explained feature importance and \nmodel insights",
        "similarity_threshold": 0.8
      },
      {
        "part_id": "Project ID",
        "type": "",
        "description": "Title\n\nDescription",
        "expected_text": "Expected Outputs"
      }
    ]
  },
  {
    "id": "LR_010",
    "title": "Your task is to build an Extra \nTrees Regressor model to \npredict the selling price \nof the cars.",
    "description": "You are provided with a dataset containing various features of \nused cars such as make, model, year, mileage, engine size, and \nmore. Your task is to build an Extra Trees Regressor model to \npredict the selling price of the cars. You need to preprocess the \ndata properly, perform feature encoding, tune hyperparameters of \nthe Extra Trees model, evaluate the models performance, \nand identify key features affecting the car price.\n\nDataset Paths: https://www.kaggle.com/datasets/\nnehalbirla/vehicle-dataset-from-car\ndekho\n\nParts: Data Preprocessing,\nHyperparameter Tuning, Model Training \n& Predictions,Model Evaluation &\nInterpretation\n\nExpected Outputs: Appropriate encoding, no errors in preprocessing,\nFound sensible best\nparameters,Successful predictions on test set,\nRMSE ~1.5, R\u00b2 ~0.9+;\nmeaningful feature importance analysis\n\nValidation Method: Text similarity,Code execution,CSV \nsimilarity,Regression evaluation\n\nSolution File: https://drive.google.com/drive/folders/16SBn96\nJVI5-ruYHiEsLlQGfO2sF-63lJ?usp=drive_link",
    "datasets": {},
    "parts": [
      {
        "part_id": "Data Preprocessing",
        "type": "",
        "description": "Part 1:Data Preprocessing\n\nHandled categorical encoding and missing values correctly",
        "similarity_threshold": 0.8
      },
      {
        "part_id": "Hyperparameter Tuning",
        "type": "",
        "description": "Part 2:Hyperparameter \nTuning\n\nUsed GridSearchCV or similar\nfor Extra Trees tuning",
        "similarity_threshold": 0.8
      },
      {
        "part_id": "Model Training & \npredictions",
        "type": "",
        "description": "Part 3:Model Training & \npredictions\n\nTrained model and made\npredictions without error",
        "similarity_threshold": 0.8
      },
      {
        "part_id": "Model evaluation & \ninterpretation",
        "type": "",
        "description": "Part 4: Model evaluation & \ninterpretation\n\nReported RMSE &amp; R\u00b2;\ninterpreted feature importance\ncorrectly",
        "similarity_threshold": 0.8
      }
    ]
  }
]